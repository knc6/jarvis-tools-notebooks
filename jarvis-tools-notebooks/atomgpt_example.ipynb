{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNMmtu7gW9a7AZ6cGPNOGPW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/knc6/jarvis-tools-notebooks/blob/master/jarvis-tools-notebooks/atomgpt_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AtomGPT example: https://pubs.acs.org/doi/10.1021/acs.jpclett.4c01126\n"
      ],
      "metadata": {
        "id": "TkkuV4Hyib2K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Table of contents\n",
        "\n",
        "1. Installing [AtomGPT](https://github.com/usnistgov/atomgpt)\n",
        "2. Example inverse model training for 5 materials\n",
        "3. Using the trained model for inference\n",
        "4. Relaxing structures with ALIGNN-FF\n",
        "5. Generating a database of atomic structures\n",
        "\n",
        "\n",
        "Author: Kamal Choudhary (kamal.choudhary@nist.gov)"
      ],
      "metadata": {
        "id": "bhdCyKO2tSeu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HURIAsbZgMF",
        "outputId": "5ecc6527-f819-42f3-a868-4b7f23d2d47c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è¨ Downloading https://github.com/jaimergp/miniforge/releases/download/24.11.2-1_colab/Miniforge3-colab-24.11.2-1_colab-Linux-x86_64.sh...\n",
            "üì¶ Installing...\n",
            "üìå Adjusting configuration...\n",
            "ü©π Patching environment...\n",
            "‚è≤ Done in 0:00:13\n",
            "üîÅ Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation"
      ],
      "metadata": {
        "id": "ZfBX7ilpiouF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import os\n",
        "os.chdir('/content')\n",
        "!rm -rf Software\n",
        "os.makedirs('/content/Software')\n",
        "os.chdir('/content/Software')\n",
        "if not os.path.exists('atomgpt'):\n",
        "  !rm -rf atomgpt\n",
        "  !git clone https://github.com/usnistgov/atomgpt.git\n",
        "  os.chdir('atomgpt')\n",
        "  !pip install -q -e .\n",
        "\n"
      ],
      "metadata": {
        "id": "SLbIamvfsqHm",
        "outputId": "fc22dd14-eb2c-4725-d676-283a362bdc27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'atomgpt'...\n",
            "remote: Enumerating objects: 904, done.\u001b[K\n",
            "remote: Counting objects: 100% (186/186), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 904 (delta 105), reused 107 (delta 56), pack-reused 718 (from 1)\u001b[K\n",
            "Receiving objects: 100% (904/904), 66.34 MiB | 16.57 MiB/s, done.\n",
            "Resolving deltas: 100% (489/489), done.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m108.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m126.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m122.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m785.0/785.0 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m115.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m809.2/809.2 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m119.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m222.6/222.6 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m146.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m120.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m123.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for multidict (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: Legacy editable install of atomgpt==2024.11.30 from file:///content/Software/atomgpt (setup.py develop) is deprecated. pip 25.0 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n",
            "\u001b[0mCPU times: user 1.29 s, sys: 227 ms, total: 1.51 s\n",
            "Wall time: 4min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q jarvis_leaderboard"
      ],
      "metadata": {
        "id": "5s-xshg4Ksls",
        "outputId": "f9728401-41bb-4a9c-d31a-2e1d8b7d1c81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.1/72.1 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m153.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check import\n",
        "import atomgpt\n",
        "import os\n",
        "os.environ.pop('MPLBACKEND', None)  # Remove the invalid backend\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')  # Use a compatible backend\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "metadata": {
        "id": "A57B4HSIKsiJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!jarvis_populate_data.py --benchmark_file AI-SinglePropertyPrediction-exfoliation_energy-dft_3d-test-mae --output_path=Out"
      ],
      "metadata": {
        "id": "PJCSrGz9KwqU",
        "outputId": "f71126c9-6b8b-453f-aa02-45263497685f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "benchmark_file AI-SinglePropertyPrediction-exfoliation_energy-dft_3d-test-mae\n",
            "dataset dft_3d\n",
            "output_path Out\n",
            "property exfoliation_energy\n",
            "method AI\n",
            "task SinglePropertyPrediction\n",
            "id_tag jid\n",
            "out_format poscar\n",
            "dataset file to be used /usr/local/lib/python3.11/site-packages/jarvis_leaderboard/benchmarks/AI/SinglePropertyPrediction/dft_3d_exfoliation_energy.json.zip\n",
            "Currently for atomistic datasets only.\n",
            "https://jarvis-tools.readthedocs.io/en/master/databases.html\n",
            "Obtaining 3D dataset 76k ...\n",
            "Reference:https://www.nature.com/articles/s41524-020-00440-1\n",
            "Other versions:https://doi.org/10.6084/m9.figshare.6815699\n",
            "100% 40.8M/40.8M [00:03<00:00, 10.9MiB/s]\n",
            "Loading the zipfile...\n",
            "Loading completed.\n",
            "number of training samples 650\n",
            "number of validation samples 81\n",
            "number of test samples 81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jarvis.db.jsonutils import loadjson,dumpjson\n",
        "dataset_info = loadjson('Out/dataset_info.json')\n",
        "#print(dataset_info)\n",
        "n_train = dataset_info['n_train']\n",
        "n_val = dataset_info['n_val']\n",
        "n_test = dataset_info['n_test']"
      ],
      "metadata": {
        "id": "yzy3HXrrKwne"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_config={'id_prop_path': \"Out/id_prop.csv\",\n",
        " 'prefix': 'atomgpt_run',\n",
        " 'model_name': \"knc6/atomgpt_mistral_tc_supercon\",\n",
        " 'batch_size': 2,\n",
        " 'num_epochs': 5,\n",
        " 'seed_val': 42,\n",
        " 'num_train': 2,\n",
        " 'num_val': 2,\n",
        " 'num_test': 2,\n",
        " 'model_save_path': 'lora_model_m'}\n",
        "dumpjson(data=temp_config,filename='atomgpt_inverse_config.json')"
      ],
      "metadata": {
        "id": "iBA_lyw7LjEi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "qa7fheaiLYgp",
        "outputId": "4d9e3041-c2d1-49cd-d1ed-f1ffdd811f8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Software/atomgpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!atomgpt_inverse_train --config_name atomgpt_inverse_config.json"
      ],
      "metadata": {
        "id": "WOZMra5rKwig",
        "outputId": "8481f1bf-bb81-4113-8bf2-ab6e5fdf6fdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_save_path\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "\n",
            "         _                   _____ _____ _______ \n",
            "    /\\  | |                 / ____|  __ \\__   __|\n",
            "   /  \\ | |_ ___  _ __ ___ | |  __| |__) | | |   \n",
            "  / /\\ \\| __/ _ \\| '_ ` _ \\| | |_ |  ___/  | |   \n",
            " / ____ \\ || (_) | | | | | | |__| | |      | |   \n",
            "/_/    \\_\\__\\___/|_| |_| |_|\\_____|_|      |_|   \n",
            "   \n",
            "config_file atomgpt_inverse_config.json\n",
            "{'alpaca_prompt': '### Instruction:\\n{}\\n### Input:\\n{}\\n### Output:\\n{}',\n",
            " 'batch_size': 2,\n",
            " 'chem_info': 'formula',\n",
            " 'csv_out': 'AI-AtomGen-prop-dft_3d-test-rmse.csv',\n",
            " 'dataset_num_proc': 2,\n",
            " 'dtype': None,\n",
            " 'file_format': 'poscar',\n",
            " 'gradient_accumulation_steps': 4,\n",
            " 'id_prop_path': 'Out/id_prop.csv',\n",
            " 'id_tag': 'id',\n",
            " 'instruction': 'Below is a description of a superconductor material.',\n",
            " 'learning_rate': 0.0002,\n",
            " 'load_in_4bit': True,\n",
            " 'logging_steps': 1,\n",
            " 'loss_type': 'default',\n",
            " 'lr_scheduler_type': 'linear',\n",
            " 'max_seq_length': 2048,\n",
            " 'model_name': 'knc6/atomgpt_mistral_tc_supercon',\n",
            " 'model_save_path': 'lora_model_m',\n",
            " 'num_epochs': 5,\n",
            " 'num_test': 2,\n",
            " 'num_train': 2,\n",
            " 'num_val': 2,\n",
            " 'optim': 'adamw_8bit',\n",
            " 'output_dir': 'outputs',\n",
            " 'output_prompt': ' Generate atomic structure description with lattice '\n",
            "                  'lengths, angles, coordinates and atom types.',\n",
            " 'per_device_train_batch_size': 2,\n",
            " 'prefix': 'atomgpt_run',\n",
            " 'prop': 'Tc_supercon',\n",
            " 'seed_val': 42}\n",
            "100% 812/812 [00:00<00:00, 5486.04it/s]\n",
            "config.prop Tc_supercon\n",
            "Sample:\n",
            " {'instruction': 'Below is a description of a superconductor material.', 'input': 'The chemical formula is NaZnP . The  Tc_supercon is 124.8. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.', 'output': '4.07 4.07 6.89\\n90 90 90\\nNa 0.000 0.500 0.644\\nNa 0.500 0.000 0.356\\nZn 0.000 0.000 0.000\\nZn 0.500 0.500 0.000\\nP 0.500 0.000 0.785\\nP 0.000 0.500 0.215'}\n",
            "config.prop Tc_supercon\n",
            "adapter_config.json: 100% 732/732 [00:00<00:00, 4.75MB/s]\n",
            "config.json: 100% 1.19k/1.19k [00:00<00:00, 7.85MB/s]\n",
            "   GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\n",
            "   Pytorch: 2.2.2+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "  Bfloat16 = FALSE. Xformers = 0.0.25.post1. FA = False.\n",
            "\n",
            "model.safetensors: 100% 4.13G/4.13G [00:29<00:00, 140MB/s] \n",
            "generation_config.json: 100% 155/155 [00:00<00:00, 1.17MB/s]\n",
            "tokenizer_config.json: 100% 1.02k/1.02k [00:00<00:00, 7.89MB/s]\n",
            "tokenizer.model: 100% 493k/493k [00:00<00:00, 6.49MB/s]\n",
            "special_tokens_map.json: 100% 438/438 [00:00<00:00, 3.26MB/s]\n",
            "tokenizer.json: 100% 1.80M/1.80M [00:00<00:00, 2.68MB/s]\n",
            "adapter_model.safetensors: 100% 168M/168M [00:01<00:00, 157MB/s]\n",
            "Unsloth 2024.5 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n",
            "Generating train split: 2 examples [00:00, 22.55 examples/s]\n",
            "Map: 100% 2/2 [00:00<00:00, 405.97 examples/s]\n",
            "Map (num_proc=2): 100% 2/2 [00:00<00:00,  5.30 examples/s]\n",
            "/usr/local/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
            "  warnings.warn(\n",
            "Num GPUs = 1\n",
            "Num examples = 2 | Num Epochs = 5\n",
            "Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "Total batch size = 8 | Total steps = 5\n",
            "Number of trainable parameters = 41,943,040\n",
            "{'loss': 0.3134, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 1.0}\n",
            "{'loss': 0.3134, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 2.0}\n",
            "{'loss': 0.3134, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 3.0}\n",
            "{'loss': 0.3134, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 4.0}\n",
            "{'loss': 0.3134, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 5.0}\n",
            "{'train_runtime': 15.0322, 'train_samples_per_second': 0.665, 'train_steps_per_second': 0.333, 'train_loss': 0.31335602402687074, 'epoch': 5.0}\n",
            "100% 5/5 [00:15<00:00,  3.01s/it]\n",
            "   GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\n",
            "   Pytorch: 2.2.2+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "  Bfloat16 = FALSE. Xformers = 0.0.25.post1. FA = False.\n",
            "\n",
            "{'alpaca_prompt': '### Instruction:\\n{}\\n### Input:\\n{}\\n### Output:\\n{}',\n",
            " 'batch_size': 2,\n",
            " 'chem_info': 'formula',\n",
            " 'csv_out': 'AI-AtomGen-prop-dft_3d-test-rmse.csv',\n",
            " 'dataset_num_proc': 2,\n",
            " 'dtype': None,\n",
            " 'file_format': 'poscar',\n",
            " 'gradient_accumulation_steps': 4,\n",
            " 'id_prop_path': 'Out/id_prop.csv',\n",
            " 'id_tag': 'id',\n",
            " 'instruction': 'Below is a description of a superconductor material.',\n",
            " 'learning_rate': 0.0002,\n",
            " 'load_in_4bit': True,\n",
            " 'logging_steps': 1,\n",
            " 'loss_type': 'default',\n",
            " 'lr_scheduler_type': 'linear',\n",
            " 'max_seq_length': 2048,\n",
            " 'model_name': 'knc6/atomgpt_mistral_tc_supercon',\n",
            " 'model_save_path': 'lora_model_m',\n",
            " 'num_epochs': 5,\n",
            " 'num_test': 2,\n",
            " 'num_train': 2,\n",
            " 'num_val': 2,\n",
            " 'optim': 'adamw_8bit',\n",
            " 'output_dir': 'outputs',\n",
            " 'output_prompt': ' Generate atomic structure description with lattice '\n",
            "                  'lengths, angles, coordinates and atom types.',\n",
            " 'per_device_train_batch_size': 2,\n",
            " 'prefix': 'atomgpt_run',\n",
            " 'prop': 'Tc_supercon',\n",
            " 'seed_val': 42}\n",
            "   GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\n",
            "   Pytorch: 2.2.2+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "  Bfloat16 = FALSE. Xformers = 0.0.25.post1. FA = False.\n",
            "\n",
            "Testing\n",
            " 2\n",
            "  0% 0/2 [00:00<?, ?it/s]response <s>### Instruction:\n",
            "Below is a description of a superconductor material.\n",
            "### Input:\n",
            "The chemical formula is UI3 . The  Tc_supercon is 98.21. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\n",
            "### Output:\n",
            "4.78 4.78 6.11\n",
            "90 90 120\n",
            "U 0.000 0.000 0.000\n",
            "I 0.333 0.667 0.667\n",
            "I 0.667 0.333 0.333\n",
            "I 0.000 0.000 0.333</s>\n",
            "target_mat System\n",
            "1.0\n",
            "4.18 0.0 0.0\n",
            "-2.04799 7.14217 0.0\n",
            "0.0 0.0 9.96\n",
            "U I \n",
            "2 6 \n",
            "direct\n",
            "0.738 0.476 0.25 U\n",
            "0.262 0.524 0.75 U\n",
            "0.354 0.709 0.434 I\n",
            "0.646 0.291 0.566 I\n",
            "0.923 0.847 0.75 I\n",
            "0.077 0.153 0.25 I\n",
            "0.354 0.709 0.066 I\n",
            "0.646 0.291 0.934 I\n",
            "\n",
            "genmat System\n",
            "1.0\n",
            "4.78 0.0 0.0\n",
            "-2.39 4.1396 0.0\n",
            "0.0 0.0 6.11\n",
            "U I \n",
            "1 3 \n",
            "direct\n",
            "0.0 0.0 0.0 U\n",
            "0.333 0.667 0.667 I\n",
            "0.667 0.333 0.333 I\n",
            "0.0 0.0 0.333 I\n",
            "\n",
            " 50% 1/2 [00:08<00:08,  8.52s/it]response <s>### Instruction:\n",
            "Below is a description of a superconductor material.\n",
            "### Input:\n",
            "The chemical formula is TiNCl . The  Tc_supercon is 39.4. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\n",
            "### Output:\n",
            "3.08 3.11 6.88\n",
            "90 101 90\n",
            "Ti 0.499 0.000 0.133\n",
            "Ti 0.501 0.000 0.867\n",
            "N 0.999 0.000 0.500\n",
            "N 0.001 0.000 0.000\n",
            "Cl 0.499 0.000 0.657\n",
            "Cl 0.501 0.000 0.343</s>\n",
            "target_mat System\n",
            "1.0\n",
            "3.27 0.0 0.0\n",
            "0.0 3.95 0.0\n",
            "0.0 0.0 7.81\n",
            "Ti N Cl \n",
            "2 2 2 \n",
            "direct\n",
            "0.5 0.0 0.099 Ti\n",
            "0.0 0.5 0.901 Ti\n",
            "0.0 0.0 0.951 N\n",
            "0.5 0.5 0.049 N\n",
            "0.5 0.5 0.666 Cl\n",
            "0.0 0.0 0.334 Cl\n",
            "\n",
            "genmat System\n",
            "1.0\n",
            "3.02341 0.0 -0.58769\n",
            "0.0 3.11 0.0\n",
            "0.0 0.0 6.88\n",
            "Ti N Cl \n",
            "2 2 2 \n",
            "direct\n",
            "0.499 0.0 0.133 Ti\n",
            "0.501 0.0 0.867 Ti\n",
            "0.999 0.0 0.5 N\n",
            "0.001 0.0 0.0 N\n",
            "0.499 0.0 0.657 Cl\n",
            "0.501 0.0 0.343 Cl\n",
            "\n",
            "100% 2/2 [00:16<00:00,  8.48s/it]\n",
            "Time taken: 149.5400071144104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zqgAPEOSKsf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RyKaHFL0Ksdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l39PFc7MKsbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yLZEzWHhKsZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training forward/inverse models with AtomGPT requires:\n",
        "\n",
        "# 1) `config.json` file, 2) `id_prop.csv` file."
      ],
      "metadata": {
        "id": "syLLDPebB04Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Example inverse model training for 5 materials"
      ],
      "metadata": {
        "id": "HhAC-Tfetscz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inverse Model Example"
      ],
      "metadata": {
        "id": "DVt6XyJjiUVv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to use default config:\n",
        "\n",
        "TrainingPropConfig(id_prop_path='id_prop.csv', prefix='atomgpt_run', model_name='unsloth/mistral-7b-bnb-4bit', batch_size=2, num_epochs=2, seed_val=42, num_train=2, num_val=2, num_test=2, model_save_path='lora_model_m')\n"
      ],
      "metadata": {
        "id": "t7t4PWmRA6zK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to use a small id_prop.csv dataset with 5 materials only for training as given [here](https://github.com/usnistgov/atomgpt/blob/main/atomgpt/examples/inverse_model/id_prop.csv) . For production results, use larger dataset.\n",
        "\n",
        "\n",
        "\n",
        "An example for creating a sample id_prop.csv for `\"optb88vdw_bandgap\"` bandgap is kept [here](https://github.com/usnistgov/alignn/blob/main/alignn/examples/sample_data/scripts/generate_sample_data_reg.py). For superconductor database use `\"Tc_supercon\"` key instead."
      ],
      "metadata": {
        "id": "b8hLHzxCBJ_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets' look at an example config file before running the training\n",
        "import os\n",
        "os.chdir('/content')\n",
        "from jarvis.db.jsonutils import loadjson,dumpjson\n",
        "import pprint\n",
        "config = loadjson('Software/atomgpt/atomgpt/examples/inverse_model/config.json')\n",
        "# config['model_name'] = \"knc6/atomgpt_mistral_tc_supercon\"\n",
        "dumpjson(data=config,filename='Software/atomgpt/atomgpt/examples/inverse_model/config.json')\n",
        "pprint.pprint(config)"
      ],
      "metadata": {
        "id": "ZrHsPD2VoxtO",
        "outputId": "309f7d29-7ae4-4238-d5c8-751835436b3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'alpaca_prompt': '### Instruction:\\n{}\\n### Input:\\n{}\\n### Output:\\n{}',\n",
            " 'batch_size': 2,\n",
            " 'chem_info': 'formula',\n",
            " 'csv_out': 'AI-AtomGen-prop-dft_3d-test-rmse.csv',\n",
            " 'dataset_num_proc': 2,\n",
            " 'dtype': None,\n",
            " 'gradient_accumulation_steps': 4,\n",
            " 'id_prop_path': 'atomgpt/examples/inverse_model/id_prop.csv',\n",
            " 'instruction': 'Below is a description of a superconductor material.',\n",
            " 'learning_rate': 0.0002,\n",
            " 'load_in_4bit': True,\n",
            " 'logging_steps': 1,\n",
            " 'loss_type': 'default',\n",
            " 'lr_scheduler_type': 'linear',\n",
            " 'max_seq_length': 2048,\n",
            " 'model_name': 'knc6/atomgpt_mistral_tc_supercon',\n",
            " 'model_save_path': 'lora_model_m',\n",
            " 'num_epochs': 2,\n",
            " 'num_test': 2,\n",
            " 'num_train': 2,\n",
            " 'num_val': 0,\n",
            " 'optim': 'adamw_8bit',\n",
            " 'output_dir': 'outputs',\n",
            " 'output_prompt': ' Generate atomic structure description with lattice '\n",
            "                  'lengths, angles, coordinates and atom types.',\n",
            " 'per_device_train_batch_size': 2,\n",
            " 'prefix': 'atomgpt_run',\n",
            " 'seed_val': 3407}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/Software/atomgpt')\n",
        "!atomgpt_inverse_train --config_name atomgpt/examples/inverse_model/config.json\n",
        "#!python Software/atomgpt/atomgpt/inverse_models/inverse_models.py --config_name Software/atomgpt/atomgpt/examples/inverse_model/config.json"
      ],
      "metadata": {
        "id": "dPgJz-gxG5e5",
        "outputId": "521b30d9-9fa1-4fb6-9a3f-d3c94daa3074",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_save_path\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "\n",
            "         _                   _____ _____ _______ \n",
            "    /\\  | |                 / ____|  __ \\__   __|\n",
            "   /  \\ | |_ ___  _ __ ___ | |  __| |__) | | |   \n",
            "  / /\\ \\| __/ _ \\| '_ ` _ \\| | |_ |  ___/  | |   \n",
            " / ____ \\ || (_) | | | | | | |__| | |      | |   \n",
            "/_/    \\_\\__\\___/|_| |_| |_|\\_____|_|      |_|   \n",
            "   \n",
            "config_file atomgpt/examples/inverse_model/config.json\n",
            "{'alpaca_prompt': '### Instruction:\\n{}\\n### Input:\\n{}\\n### Output:\\n{}',\n",
            " 'batch_size': 2,\n",
            " 'chem_info': 'formula',\n",
            " 'csv_out': 'AI-AtomGen-prop-dft_3d-test-rmse.csv',\n",
            " 'dataset_num_proc': 2,\n",
            " 'dtype': None,\n",
            " 'file_format': 'poscar',\n",
            " 'gradient_accumulation_steps': 4,\n",
            " 'id_prop_path': 'atomgpt/examples/inverse_model/id_prop.csv',\n",
            " 'id_tag': 'id',\n",
            " 'instruction': 'Below is a description of a superconductor material.',\n",
            " 'learning_rate': 0.0002,\n",
            " 'load_in_4bit': True,\n",
            " 'logging_steps': 1,\n",
            " 'loss_type': 'default',\n",
            " 'lr_scheduler_type': 'linear',\n",
            " 'max_seq_length': 2048,\n",
            " 'model_name': 'knc6/atomgpt_mistral_tc_supercon',\n",
            " 'model_save_path': 'lora_model_m',\n",
            " 'num_epochs': 2,\n",
            " 'num_test': 2,\n",
            " 'num_train': 2,\n",
            " 'num_val': 0,\n",
            " 'optim': 'adamw_8bit',\n",
            " 'output_dir': 'outputs',\n",
            " 'output_prompt': ' Generate atomic structure description with lattice '\n",
            "                  'lengths, angles, coordinates and atom types.',\n",
            " 'per_device_train_batch_size': 2,\n",
            " 'prefix': 'atomgpt_run',\n",
            " 'prop': 'Tc_supercon',\n",
            " 'seed_val': 3407}\n",
            "\r  0% 0/6 [00:00<?, ?it/s]\r100% 6/6 [00:00<00:00, 301.74it/s]\n",
            "outputs/alpaca_prop_train.json  exists\n",
            "Sample:\n",
            " {'instruction': 'Below is a description of a superconductor material.', 'input': 'The chemical formula is NaZnP . The  Tc_supercon is 124.8. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.', 'output': '4.07 4.07 6.89\\n90 90 90\\nNa 0.000 0.500 0.644\\nNa 0.500 0.000 0.356\\nZn 0.000 0.000 0.000\\nZn 0.500 0.500 0.000\\nP 0.500 0.000 0.785\\nP 0.000 0.500 0.215'}\n",
            "outputs/alpaca_prop_test.json exists\n",
            "   GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\n",
            "   Pytorch: 2.2.2+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "  Bfloat16 = FALSE. Xformers = 0.0.25.post1. FA = False.\n",
            "\n",
            "Unsloth 2024.5 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n",
            "Map (num_proc=2): 100% 2/2 [00:00<00:00,  5.07 examples/s]\n",
            "/usr/local/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
            "  warnings.warn(\n",
            "Num GPUs = 1\n",
            "Num examples = 2 | Num Epochs = 2\n",
            "Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "Total batch size = 8 | Total steps = 2\n",
            "Number of trainable parameters = 41,943,040\n",
            "{'loss': 0.3134, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 1.0}\n",
            "{'loss': 0.3134, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 2.0}\n",
            "{'train_runtime': 6.4812, 'train_samples_per_second': 0.617, 'train_steps_per_second': 0.309, 'train_loss': 0.31335602700710297, 'epoch': 2.0}\n",
            "100% 2/2 [00:06<00:00,  3.24s/it]\n",
            "   GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\n",
            "   Pytorch: 2.2.2+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "  Bfloat16 = FALSE. Xformers = 0.0.25.post1. FA = False.\n",
            "\n",
            "{'alpaca_prompt': '### Instruction:\\n{}\\n### Input:\\n{}\\n### Output:\\n{}',\n",
            " 'batch_size': 2,\n",
            " 'chem_info': 'formula',\n",
            " 'csv_out': 'AI-AtomGen-prop-dft_3d-test-rmse.csv',\n",
            " 'dataset_num_proc': 2,\n",
            " 'dtype': None,\n",
            " 'file_format': 'poscar',\n",
            " 'gradient_accumulation_steps': 4,\n",
            " 'id_prop_path': 'atomgpt/examples/inverse_model/id_prop.csv',\n",
            " 'id_tag': 'id',\n",
            " 'instruction': 'Below is a description of a superconductor material.',\n",
            " 'learning_rate': 0.0002,\n",
            " 'load_in_4bit': True,\n",
            " 'logging_steps': 1,\n",
            " 'loss_type': 'default',\n",
            " 'lr_scheduler_type': 'linear',\n",
            " 'max_seq_length': 2048,\n",
            " 'model_name': 'knc6/atomgpt_mistral_tc_supercon',\n",
            " 'model_save_path': 'lora_model_m',\n",
            " 'num_epochs': 2,\n",
            " 'num_test': 2,\n",
            " 'num_train': 2,\n",
            " 'num_val': 0,\n",
            " 'optim': 'adamw_8bit',\n",
            " 'output_dir': 'outputs',\n",
            " 'output_prompt': ' Generate atomic structure description with lattice '\n",
            "                  'lengths, angles, coordinates and atom types.',\n",
            " 'per_device_train_batch_size': 2,\n",
            " 'prefix': 'atomgpt_run',\n",
            " 'prop': 'Tc_supercon',\n",
            " 'seed_val': 3407}\n",
            "   GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\n",
            "   Pytorch: 2.2.2+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "  Bfloat16 = FALSE. Xformers = 0.0.25.post1. FA = False.\n",
            "\n",
            "Testing\n",
            " 2\n",
            "  0% 0/2 [00:00<?, ?it/s]response <s>### Instruction:\n",
            "Below is a description of a superconductor material.\n",
            "### Input:\n",
            "The chemical formula is UI3 . The  Tc_supercon is 98.21. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\n",
            "### Output:\n",
            "4.78 4.78 6.11\n",
            "90 90 120\n",
            "U 0.000 0.000 0.000\n",
            "I 0.333 0.667 0.667\n",
            "I 0.667 0.333 0.333\n",
            "I 0.000 0.000 0.333</s>\n",
            "target_mat System\n",
            "1.0\n",
            "4.18 0.0 0.0\n",
            "-2.04799 7.14217 0.0\n",
            "0.0 0.0 9.96\n",
            "U I \n",
            "2 6 \n",
            "direct\n",
            "0.738 0.476 0.25 U\n",
            "0.262 0.524 0.75 U\n",
            "0.354 0.709 0.434 I\n",
            "0.646 0.291 0.566 I\n",
            "0.923 0.847 0.75 I\n",
            "0.077 0.153 0.25 I\n",
            "0.354 0.709 0.066 I\n",
            "0.646 0.291 0.934 I\n",
            "\n",
            "genmat System\n",
            "1.0\n",
            "4.78 0.0 0.0\n",
            "-2.39 4.1396 0.0\n",
            "0.0 0.0 6.11\n",
            "U I \n",
            "1 3 \n",
            "direct\n",
            "0.0 0.0 0.0 U\n",
            "0.333 0.667 0.667 I\n",
            "0.667 0.333 0.333 I\n",
            "0.0 0.0 0.333 I\n",
            "\n",
            " 50% 1/2 [00:07<00:07,  7.45s/it]response <s>### Instruction:\n",
            "Below is a description of a superconductor material.\n",
            "### Input:\n",
            "The chemical formula is TiNCl . The  Tc_supercon is 39.4. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\n",
            "### Output:\n",
            "3.08 3.11 6.88\n",
            "90 101 90\n",
            "Ti 0.499 0.000 0.133\n",
            "Ti 0.501 0.000 0.867\n",
            "N 0.999 0.000 0.500\n",
            "N 0.001 0.000 0.000\n",
            "Cl 0.499 0.000 0.657\n",
            "Cl 0.501 0.000 0.343</s>\n",
            "target_mat System\n",
            "1.0\n",
            "3.27 0.0 0.0\n",
            "0.0 3.95 0.0\n",
            "0.0 0.0 7.81\n",
            "Ti N Cl \n",
            "2 2 2 \n",
            "direct\n",
            "0.5 0.0 0.099 Ti\n",
            "0.0 0.5 0.901 Ti\n",
            "0.0 0.0 0.951 N\n",
            "0.5 0.5 0.049 N\n",
            "0.5 0.5 0.666 Cl\n",
            "0.0 0.0 0.334 Cl\n",
            "\n",
            "genmat System\n",
            "1.0\n",
            "3.02341 0.0 -0.58769\n",
            "0.0 3.11 0.0\n",
            "0.0 0.0 6.88\n",
            "Ti N Cl \n",
            "2 2 2 \n",
            "direct\n",
            "0.499 0.0 0.133 Ti\n",
            "0.501 0.0 0.867 Ti\n",
            "0.999 0.0 0.5 N\n",
            "0.001 0.0 0.0 N\n",
            "0.499 0.0 0.657 Cl\n",
            "0.501 0.0 0.343 Cl\n",
            "\n",
            "100% 2/2 [00:16<00:00,  8.31s/it]\n",
            "Time taken: 75.54917502403259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from atomgpt.inverse_models.inverse_models import gen_atoms\n",
        "# from atomgpt.inverse_models import  FastLanguageModel\n",
        "\n",
        "# alpaca_prompt = \"\"\"Below is a description of a superconductor material..\n",
        "\n",
        "# ### Instruction:\n",
        "# {}\n",
        "\n",
        "# ### Input:\n",
        "# {}\n",
        "\n",
        "# ### Output:\n",
        "# {}\"\"\"\n",
        "\n",
        "# max_seq_length = 2048  # Choose any! We auto support RoPE Scaling internally!\n",
        "# dtype = None  #\n",
        "# load_in_4bit = True\n",
        "# model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "#     model_name = \"lora_model_m\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "#     max_seq_length = max_seq_length,\n",
        "#     dtype = dtype,\n",
        "#     load_in_4bit = load_in_4bit,\n",
        "#     device_map=\"auto\"\n",
        "\n",
        "# )\n",
        "# FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "\n",
        "# # Example prompt and generated structure\n",
        "# if __name__==\"__main__\":\n",
        "#  prompt_example = \"The chemical formula is FeBN The  prop is 36.483. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\"\n",
        "\n",
        "#  gen_mat = gen_atoms(prompt=prompt_example,model=model,tokenizer=tokenizer)\n",
        "#  print(gen_mat)"
      ],
      "metadata": {
        "id": "5FDQhK6MX5Tt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python atomgpt/inverse_models/inverse_predict.py --output_dir outputs/ --pred_csv \"atomgpt/examples/inverse_model/pred_list_inverse.csv\""
      ],
      "metadata": {
        "id": "DW_eXcZfX5Mq",
        "outputId": "ea885f2b-032a-42b0-9623-99b4cc602bb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_save_path\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "{'alpaca_prompt': '### Instruction:\\n{}\\n### Input:\\n{}\\n### Output:\\n{}',\n",
            " 'batch_size': 2,\n",
            " 'chem_info': 'formula',\n",
            " 'csv_out': 'AI-AtomGen-prop-dft_3d-test-rmse.csv',\n",
            " 'dataset_num_proc': 2,\n",
            " 'dtype': None,\n",
            " 'file_format': 'poscar',\n",
            " 'gradient_accumulation_steps': 4,\n",
            " 'id_prop_path': 'atomgpt/examples/inverse_model/id_prop.csv',\n",
            " 'id_tag': 'id',\n",
            " 'instruction': 'Below is a description of a superconductor material.',\n",
            " 'learning_rate': 0.0002,\n",
            " 'load_in_4bit': True,\n",
            " 'logging_steps': 1,\n",
            " 'loss_type': 'default',\n",
            " 'lr_scheduler_type': 'linear',\n",
            " 'max_seq_length': 2048,\n",
            " 'model_name': 'knc6/atomgpt_mistral_tc_supercon',\n",
            " 'model_save_path': 'lora_model_m',\n",
            " 'num_epochs': 2,\n",
            " 'num_test': 2,\n",
            " 'num_train': 2,\n",
            " 'num_val': 0,\n",
            " 'optim': 'adamw_8bit',\n",
            " 'output_dir': 'outputs',\n",
            " 'output_prompt': ' Generate atomic structure description with lattice '\n",
            "                  'lengths, angles, coordinates and atom types.',\n",
            " 'per_device_train_batch_size': 2,\n",
            " 'prefix': 'atomgpt_run',\n",
            " 'prop': 'Tc_supercon',\n",
            " 'seed_val': 3407}\n",
            "   GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\n",
            "   Pytorch: 2.2.2+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "  Bfloat16 = FALSE. Xformers = 0.0.25.post1. FA = False.\n",
            "\n",
            "Unsloth 2024.5 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n",
            "prompt The chemical formula is FeBN. The  prop is 36.483. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\n",
            "response <s>### Instruction:\n",
            "Below is a description of a superconductor material.\n",
            "### Input:\n",
            "The chemical formula is FeBN. The  prop is 36.483. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\n",
            "### Output:\n",
            "3.02 3.05 5.11\n",
            "90 108 90\n",
            "Fe 0.853 0.000 0.292\n",
            "Fe 0.147 0.000 0.708\n",
            "B 0.579 0.000 0.005\n",
            "B 0.421 0.000 0.995\n",
            "N 0.256 0.571 0.628\n",
            "N 0.744 0.429 0.372</s>\n",
            "gen atoms System\n",
            "1.0\n",
            "2.87219 0.0 -0.93323\n",
            "0.0 3.05 0.0\n",
            "0.0 0.0 5.11\n",
            "Fe B N \n",
            "2 2 2 \n",
            "direct\n",
            "0.853 0.0 0.292 Fe\n",
            "0.147 0.0 0.708 Fe\n",
            "0.579 0.0 0.005 B\n",
            "0.421 0.0 0.995 B\n",
            "0.256 0.571 0.628 N\n",
            "0.744 0.429 0.372 N\n",
            "\n",
            "prompt The chemical formula is MgC2. The  prop is 36.483. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\n",
            "response <s>### Instruction:\n",
            "Below is a description of a superconductor material.\n",
            "### Input:\n",
            "The chemical formula is MgC2. The  prop is 36.483. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\n",
            "### Output:\n",
            "3.14 3.15 5.21\n",
            "90 109 90\n",
            "Mg 0.000 0.000 0.000\n",
            "C 0.333 0.500 0.238\n",
            "C 0.667 0.500 0.762</s>\n",
            "gen atoms System\n",
            "1.0\n",
            "2.96893 0.0 -1.02228\n",
            "0.0 3.15 0.0\n",
            "0.0 0.0 5.21\n",
            "Mg C \n",
            "1 2 \n",
            "direct\n",
            "0.0 0.0 0.0 Mg\n",
            "0.333 0.5 0.238 C\n",
            "0.667 0.5 0.762 C\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-IdyEJXzX5Ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XPO4Cf4EX5H7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extras"
      ],
      "metadata": {
        "id": "Q_R0bYP6ZBFL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S0rNEtR0X5Fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "id": "yzZyPb33AEll",
        "outputId": "267dccef-a70a-404b-aa69-67463a0c672b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI-AtomGen-prop-dft_3d-test-rmse.csv  alpaca_prop_val.json\t    lora_model_m  Software\n",
            "alpaca_prop_test.json\t\t      condacolab_install.log\t    outputs\n",
            "alpaca_prop_train.json\t\t      huggingface_tokenizers_cache  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Files such as `AI-AtomGen-prop-dft_3d-test-rmse.csv ` can be uploaded in the [JARVIS-Leaderboard](https://pages.nist.gov/jarvis_leaderboard/) benchmarking plotform.\n",
        "\n"
      ],
      "metadata": {
        "id": "UUkS9YNgrBM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The models are saved in the folder `lora_model_m`"
      ],
      "metadata": {
        "id": "nvURZAxFrtVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls lora_model_m"
      ],
      "metadata": {
        "id": "Or-1ZO_arNHo",
        "outputId": "5e439d7e-6199-42e4-82b8-4d7fde6351d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adapter_config.json  adapter_model.safetensors\tREADME.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at `alpaca_prop_test.json` and `alpaca_prop_train.json`"
      ],
      "metadata": {
        "id": "f1UdRnNorUN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpaca_prop_test=loadjson('alpaca_prop_test.json')\n",
        "alpaca_prop_train=loadjson('alpaca_prop_train.json')\n",
        "print(len(alpaca_prop_test),len(alpaca_prop_train))\n",
        "print('\\n')\n",
        "pprint.pprint(alpaca_prop_train[0])\n",
        "print('\\n')\n"
      ],
      "metadata": {
        "id": "ymYpnxvErTzW",
        "outputId": "82ab0f98-3903-4b41-996f-cfcbe0a3e3ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 2\n",
            "\n",
            "\n",
            "{'input': 'The chemical formula is MgB2. The  prop is 33.0. Generate atomic '\n",
            "          'structure description with lattice lengths, angles, coordinates and '\n",
            "          'atom types.',\n",
            " 'instruction': 'Below is a description of a superconductor material.',\n",
            " 'output': '3.07 3.07 3.51\\n'\n",
            "           '90 90 119\\n'\n",
            "           'Mg 0.000 0.000 0.000\\n'\n",
            "           'B 0.667 0.333 0.500\\n'\n",
            "           'B 0.333 0.667 0.500'}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Using the trained model for inference"
      ],
      "metadata": {
        "id": "IBz34xi_tztU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's load the trained model for inference/testing. Note again this model was trained on just a few samples, so accuracy wont be very high."
      ],
      "metadata": {
        "id": "-lt2RgZmr0ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from jarvis.db.jsonutils import loadjson\n",
        "# from atomgpt.inverse_models import  FastLanguageModel\n",
        "# import torch\n",
        "# from datasets import load_dataset\n",
        "# from trl import SFTTrainer\n",
        "# from transformers import TrainingArguments\n",
        "# from jarvis.core.atoms import Atoms\n",
        "# from jarvis.db.figshare import data\n",
        "# from jarvis.db.jsonutils import loadjson, dumpjson\n",
        "# import numpy as np\n",
        "# from jarvis.core.atoms import Atoms\n",
        "# from jarvis.core.lattice import Lattice\n",
        "# from tqdm import tqdm\n",
        "# from jarvis.io.vasp.inputs import Poscar\n",
        "\n",
        "# import os\n",
        "# #os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
        "# #torch.cuda.is_available = lambda : False\n",
        "# alpaca_prompt = \"\"\"Below is a description of a superconductor material..\n",
        "\n",
        "# ### Instruction:\n",
        "# {}\n",
        "\n",
        "# ### Input:\n",
        "# {}\n",
        "\n",
        "# ### Output:\n",
        "# {}\"\"\"\n",
        "\n",
        "# max_seq_length = 2048  # Choose any! We auto support RoPE Scaling internally!\n",
        "# dtype = None  #\n",
        "# load_in_4bit = True\n",
        "# model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "#     model_name = \"lora_model_m\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "#     max_seq_length = max_seq_length,\n",
        "#     dtype = dtype,\n",
        "#     load_in_4bit = load_in_4bit,\n",
        "#     device_map=\"auto\"\n",
        "\n",
        "# )\n",
        "# FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "\n",
        "# def text2atoms(response):\n",
        "#     tmp_atoms_array = response.split(\"\\n\")\n",
        "#     lat_lengths = np.array(tmp_atoms_array[1].split(), dtype=\"float\")\n",
        "#     lat_angles = np.array(tmp_atoms_array[2].split(), dtype=\"float\")\n",
        "#     lat = Lattice.from_parameters(\n",
        "#         lat_lengths[0],\n",
        "#         lat_lengths[1],\n",
        "#         lat_lengths[2],\n",
        "#         lat_angles[0],\n",
        "#         lat_angles[1],\n",
        "#         lat_angles[2],\n",
        "#     )\n",
        "#     elements = []\n",
        "#     coords = []\n",
        "#     for ii, i in enumerate(tmp_atoms_array):\n",
        "#         if ii > 2 and ii < len(tmp_atoms_array):\n",
        "#             tmp = i.split()\n",
        "#             elements.append(tmp[0])\n",
        "#             coords.append([float(tmp[1]), float(tmp[2]), float(tmp[3])])\n",
        "#     atoms = Atoms(\n",
        "#         coords=coords,\n",
        "#         elements=elements,\n",
        "#         lattice_mat=lat.lattice(),\n",
        "#         cartesian=False,\n",
        "#     )\n",
        "#     return atoms\n",
        "\n",
        "# def gen_atoms(prompt=\"\", max_new_tokens=512, model=\"\", tokenizer=\"\"):\n",
        "#     inputs = tokenizer(\n",
        "#         [\n",
        "#             alpaca_prompt.format(\n",
        "#                 \"Below is a description of a superconductor material.\",  # instruction\n",
        "#                 prompt,  # input\n",
        "#                 \"\",  # output - leave this blank for generation!\n",
        "#             )\n",
        "#         ],\n",
        "#         return_tensors=\"pt\",\n",
        "#     ).to(\"cuda\")\n",
        "#     outputs = model.generate(\n",
        "#         **inputs, max_new_tokens=max_new_tokens, use_cache=True\n",
        "#     )\n",
        "#     response = tokenizer.batch_decode(outputs)[0].split(\"# Output:\")[1].strip('</s>')\n",
        "#     # print('response',response)\n",
        "#     atoms = text2atoms(response)\n",
        "#     return atoms\n",
        "\n",
        "# if __name__==\"__main__\":\n",
        "#  prompt_example = \"The chemical formula is MgB2 The  Tc_supercon is 6.483. The spacegroup is 12. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\"\n",
        "#  prompt_example = \"The chemical formula is FeBN The  Tc_supercon is 36.483. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\"\n",
        "\n",
        "#  gen_mat = gen_atoms(prompt=prompt_example,model=model,tokenizer=tokenizer)\n",
        "#  print(gen_mat)"
      ],
      "metadata": {
        "id": "Z0Gf0CKSr8oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Relaxing structures with ALIGNN-FF"
      ],
      "metadata": {
        "id": "SOp5oZSpt68_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The generated atomic structures can be relaxed with ALIGNN-FF, see example [here](https://colab.research.google.com/github/knc6/jarvis-tools-notebooks/blob/master/jarvis-tools-notebooks/ALIGNN_Structure_Relaxation_Phonons_Interface.ipynb)."
      ],
      "metadata": {
        "id": "wLEaeWSkstav"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above example used 5 materials during train only. We used about 1000 materials database in JARVIS-DFT, and the fine-tuned model is kept on [huggingface](https://huggingface.co/knc6/atomgpt_mistral_tc_supercon)."
      ],
      "metadata": {
        "id": "BkzSijjds4o5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Generating a database"
      ],
      "metadata": {
        "id": "IDpOtWsLuABd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from jarvis.core.specie import atomic_numbers_to_symbols\n",
        "# import numpy as np\n",
        "# from jarvis.db.jsonutils import loadjson, dumpjson\n",
        "# from jarvis.core.composition import Composition\n",
        "# from tqdm import tqdm\n",
        "# from inf import gen_atoms\n",
        "\n",
        "# Z = np.arange(100) + 1\n",
        "# els = atomic_numbers_to_symbols(Z)\n",
        "\n",
        "# m = 1\n",
        "# n = 2\n",
        "\n",
        "\n",
        "# def gen_binary_samples(element=\"B\"):\n",
        "#     mem = []\n",
        "#     for m in np.arange(1, 4):\n",
        "#         for n in np.arange(1, 4):\n",
        "#             for i in tqdm(els):\n",
        "#                 try:\n",
        "#                     comp = Composition.from_dict({i: m, element: n})\n",
        "#                     prompt_example = (\n",
        "#                         \"The chemical formula is \"\n",
        "#                         + comp.reduced_formula\n",
        "#                         + \" The  Tc_supercon is 100. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\"\n",
        "#                     )\n",
        "#                     gen_mat = gen_atoms(prompt_example)\n",
        "#                     print(i)\n",
        "#                     print(gen_mat, len(mem))\n",
        "#                     mem.append([int(m), int(n), i, gen_mat.to_dict()])\n",
        "#                     # dumpjson(data=mem,filename='superB.json')\n",
        "#                 except:\n",
        "#                     pass\n",
        "#     fname=\"binary_super\"+element+\".json\"\n",
        "#     dumpjson(data=mem, filename=fname)\n",
        "# gen_binary_samples(\"S\")\n",
        "# gen_binary_samples(\"Se\")\n",
        "# gen_binary_samples(\"Te\")\n",
        "# def gen_ternary_samples(element=\"B\"):\n",
        "#     mem = []\n",
        "#     for m in np.arange(1, 4):\n",
        "#         for n in np.arange(1, 4):\n",
        "#           for j in tqdm(els):\n",
        "#             for i in tqdm(els):\n",
        "#                 try:\n",
        "#                     comp = Composition.from_dict({i: m, j:n, element: n})\n",
        "#                     prompt_example = (\n",
        "#                         \"The chemical formula is \"\n",
        "#                         + comp.reduced_formula\n",
        "#                         + \" The  Tc_supercon is 100. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\"\n",
        "#                     )\n",
        "#                     gen_mat = gen_atoms(prompt_example)\n",
        "#                     print(i)\n",
        "#                     print(gen_mat, len(mem))\n",
        "#                     mem.append([int(m), int(n), i, gen_mat.to_dict()])\n",
        "#                     # dumpjson(data=mem,filename='superB.json')\n",
        "#                 except:\n",
        "#                     pass\n",
        "#     fname=\"binary_super\"+element+\".json\"\n",
        "#     dumpjson(data=mem, filename=fname)\n",
        "# gen_ternary_samples(\"B\")\n",
        "\n",
        "# \"\"\"\n",
        "\n",
        "# m=1\n",
        "# n=2\n",
        "# mem=[]\n",
        "# for m in np.arange(1,4):\n",
        "#   for n in np.arange(1,4):\n",
        "#     for i in tqdm(els):\n",
        "#       try:\n",
        "#         comp=Composition.from_dict({i:m,\"C\":n})\n",
        "#         prompt_example = \"The chemical formula is \"+comp.reduced_formula+\" The  Tc_supercon is 100. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\"\n",
        "#         gen_mat = gen_atoms(prompt_example)\n",
        "#         print(i)\n",
        "#         print(gen_mat,len(mem))\n",
        "#         mem.append([int(m),int(n),i,gen_mat.to_dict()])\n",
        "#         #mem.append([m,n,i,gen_mat.to_dict()])\n",
        "#       except:\n",
        "#         pass\n",
        "# dumpjson(data=mem,filename='superC.json')\n",
        "\n",
        "\n",
        "\n",
        "# m=1\n",
        "# n=2\n",
        "# mem=[]\n",
        "# for m in np.arange(1,4):\n",
        "#   for n in np.arange(1,4):\n",
        "#     for i in tqdm(els):\n",
        "#       try:\n",
        "#         comp=Composition.from_dict({i:m,\"N\":n})\n",
        "#         prompt_example = \"The chemical formula is \"+comp.reduced_formula+\" The  Tc_supercon is 100. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\"\n",
        "#         gen_mat = gen_atoms(prompt_example)\n",
        "#         print(i)\n",
        "#         print(gen_mat,len(mem))\n",
        "#         mem.append([int(m),int(n),i,gen_mat.to_dict()])\n",
        "#         #mem.append([m,n,i,gen_mat.to_dict()])\n",
        "#       except:\n",
        "#         pass\n",
        "# dumpjson(data=mem,filename='superN.json')\n",
        "# \"\"\"\n"
      ],
      "metadata": {
        "id": "k5qoILFysR-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For forward model training with AtomGPT, see https://colab.research.google.com/github/knc6/jarvis-tools-notebooks/blob/master/jarvis-tools-notebooks/atomgpt_forward_example.ipynb"
      ],
      "metadata": {
        "id": "3S-GrT1LEAMv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K_6ZFPJMsR7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g4Px2rjJz_AL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q4ulYeQizxii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Ae04L4JgC05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!conda env export"
      ],
      "metadata": {
        "id": "-IUbsYWmgCx_",
        "outputId": "66ba204b-dc5a-47f4-8221-6fe4949328cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name: base\n",
            "channels:\n",
            "  - conda-forge\n",
            "dependencies:\n",
            "  - _libgcc_mutex=0.1=conda_forge\n",
            "  - _openmp_mutex=4.5=2_gnu\n",
            "  - archspec=0.2.2=pyhd8ed1ab_0\n",
            "  - boltons=23.1.1=pyhd8ed1ab_0\n",
            "  - brotli-python=1.1.0=py310hc6cd4ac_1\n",
            "  - bzip2=1.0.8=hd590300_5\n",
            "  - c-ares=1.24.0=hd590300_0\n",
            "  - ca-certificates=2023.11.17=hbcca054_0\n",
            "  - cffi=1.16.0=py310h2fee648_0\n",
            "  - charset-normalizer=3.3.2=pyhd8ed1ab_0\n",
            "  - colorama=0.4.6=pyhd8ed1ab_0\n",
            "  - conda=23.11.0=py310hff52083_1\n",
            "  - conda-libmamba-solver=23.12.0=pyhd8ed1ab_0\n",
            "  - conda-package-handling=2.2.0=pyh38be061_0\n",
            "  - conda-package-streaming=0.9.0=pyhd8ed1ab_0\n",
            "  - distro=1.8.0=pyhd8ed1ab_0\n",
            "  - fmt=10.1.1=h00ab1b0_1\n",
            "  - icu=73.2=h59595ed_0\n",
            "  - jsonpatch=1.33=pyhd8ed1ab_0\n",
            "  - jsonpointer=2.4=py310hff52083_3\n",
            "  - keyutils=1.6.1=h166bdaf_0\n",
            "  - krb5=1.21.2=h659d440_0\n",
            "  - ld_impl_linux-64=2.40=h41732ed_0\n",
            "  - libarchive=3.7.2=h2aa1ff5_1\n",
            "  - libcurl=8.5.0=hca28451_0\n",
            "  - libedit=3.1.20191231=he28a2e2_2\n",
            "  - libev=4.33=hd590300_2\n",
            "  - libffi=3.4.2=h7f98852_5\n",
            "  - libgcc-ng=13.2.0=h807b86a_3\n",
            "  - libgomp=13.2.0=h807b86a_3\n",
            "  - libiconv=1.17=hd590300_2\n",
            "  - libmamba=1.5.5=had39da4_0\n",
            "  - libmambapy=1.5.5=py310h39ff949_0\n",
            "  - libnghttp2=1.58.0=h47da74e_1\n",
            "  - libnsl=2.0.1=hd590300_0\n",
            "  - libsolv=0.7.27=hfc55251_0\n",
            "  - libsqlite=3.44.2=h2797004_0\n",
            "  - libssh2=1.11.0=h0841786_0\n",
            "  - libstdcxx-ng=13.2.0=h7e041cc_3\n",
            "  - libuuid=2.38.1=h0b41bf4_0\n",
            "  - libxml2=2.12.3=h232c23b_0\n",
            "  - libzlib=1.2.13=hd590300_5\n",
            "  - lz4-c=1.9.4=hcb278e6_0\n",
            "  - lzo=2.10=h516909a_1000\n",
            "  - mamba=1.5.5=py310h51d5547_0\n",
            "  - menuinst=2.0.1=py310hff52083_0\n",
            "  - ncurses=6.4=h59595ed_2\n",
            "  - openssl=3.2.0=hd590300_1\n",
            "  - pip=23.3.2=pyhd8ed1ab_0\n",
            "  - pluggy=1.3.0=pyhd8ed1ab_0\n",
            "  - pybind11-abi=4=hd8ed1ab_3\n",
            "  - pycosat=0.6.6=py310h2372a71_0\n",
            "  - pycparser=2.21=pyhd8ed1ab_0\n",
            "  - pysocks=1.7.1=pyha2e5f31_6\n",
            "  - python=3.10.13=hd12c33a_0_cpython\n",
            "  - python_abi=3.10=4_cp310\n",
            "  - readline=8.2=h8228510_1\n",
            "  - reproc=14.2.4.post0=hd590300_1\n",
            "  - reproc-cpp=14.2.4.post0=h59595ed_1\n",
            "  - ruamel.yaml=0.18.5=py310h2372a71_0\n",
            "  - ruamel.yaml.clib=0.2.7=py310h2372a71_2\n",
            "  - setuptools=68.2.2=pyhd8ed1ab_0\n",
            "  - tk=8.6.13=noxft_h4845f30_101\n",
            "  - truststore=0.8.0=pyhd8ed1ab_0\n",
            "  - wheel=0.42.0=pyhd8ed1ab_0\n",
            "  - xz=5.2.6=h166bdaf_0\n",
            "  - yaml-cpp=0.8.0=h59595ed_0\n",
            "  - zstandard=0.22.0=py310h1275a96_0\n",
            "  - zstd=1.5.5=hfc55251_0\n",
            "  - pip:\n",
            "      - accelerate==0.31.0\n",
            "      - aiohttp==3.9.5\n",
            "      - aiosignal==1.3.1\n",
            "      - alignn==2024.4.20\n",
            "      - annotated-types==0.7.0\n",
            "      - ase==3.23.0\n",
            "      - async-timeout==4.0.3\n",
            "      - attrs==23.2.0\n",
            "      - autopep8==2.3.1\n",
            "      - bitsandbytes==0.43.1\n",
            "      - black==24.4.2\n",
            "      - certifi==2024.6.2\n",
            "      - chardet==3.0.4\n",
            "      - click==8.1.7\n",
            "      - contourpy==1.2.1\n",
            "      - cycler==0.12.1\n",
            "      - datasets==2.20.0\n",
            "      - dgl==1.1.1\n",
            "      - dill==0.3.8\n",
            "      - docstring-parser==0.16\n",
            "      - eval-type-backport==0.2.0\n",
            "      - filelock==3.15.4\n",
            "      - flake8==7.1.0\n",
            "      - fonttools==4.53.0\n",
            "      - frozenlist==1.4.1\n",
            "      - fsspec==2024.5.0\n",
            "      - gmpy2==2.2.1\n",
            "      - huggingface-hub==0.23.4\n",
            "      - idna==3.7\n",
            "      - importlib-resources==6.4.0\n",
            "      - jarvis-tools==2024.4.30\n",
            "      - jinja2==3.1.4\n",
            "      - joblib==1.4.2\n",
            "      - kiwisolver==1.4.5\n",
            "      - lmdb==1.4.1\n",
            "      - markdown-it-py==3.0.0\n",
            "      - markupsafe==2.1.5\n",
            "      - matplotlib==3.9.0\n",
            "      - mccabe==0.7.0\n",
            "      - mdurl==0.1.2\n",
            "      - mpmath==1.3.0\n",
            "      - multidict==4.7.6\n",
            "      - multiprocess==0.70.16\n",
            "      - mypy-extensions==1.0.0\n",
            "      - networkx==3.3\n",
            "      - numpy==1.26.4\n",
            "      - nvidia-cublas-cu12==12.1.3.1\n",
            "      - nvidia-cuda-cupti-cu12==12.1.105\n",
            "      - nvidia-cuda-nvrtc-cu12==12.1.105\n",
            "      - nvidia-cuda-runtime-cu12==12.1.105\n",
            "      - nvidia-cudnn-cu12==8.9.2.26\n",
            "      - nvidia-cufft-cu12==11.0.2.54\n",
            "      - nvidia-curand-cu12==10.3.2.106\n",
            "      - nvidia-cusolver-cu12==11.4.5.107\n",
            "      - nvidia-cusparse-cu12==12.1.0.106\n",
            "      - nvidia-nccl-cu12==2.19.3\n",
            "      - nvidia-nvjitlink-cu12==12.6.20\n",
            "      - nvidia-nvtx-cu12==12.1.105\n",
            "      - packaging==24.1\n",
            "      - pandas==2.2.2\n",
            "      - pathspec==0.12.1\n",
            "      - peft==0.11.1\n",
            "      - pillow==10.3.0\n",
            "      - platformdirs==4.2.2\n",
            "      - protobuf==5.27.3\n",
            "      - psutil==6.0.0\n",
            "      - pyarrow==16.1.0\n",
            "      - pyarrow-hotfix==0.6\n",
            "      - pycodestyle==2.12.0\n",
            "      - pydantic==2.7.4\n",
            "      - pydantic-core==2.18.4\n",
            "      - pydantic-settings==2.3.3\n",
            "      - pydocstyle==6.3.0\n",
            "      - pyflakes==3.2.0\n",
            "      - pygments==2.18.0\n",
            "      - pyparsing==2.4.7\n",
            "      - python-dateutil==2.9.0.post0\n",
            "      - python-dotenv==1.0.1\n",
            "      - pytz==2024.1\n",
            "      - pyyaml==6.0.2\n",
            "      - regex==2024.5.15\n",
            "      - requests==2.32.3\n",
            "      - rich==13.7.1\n",
            "      - safetensors==0.4.3\n",
            "      - scikit-learn==1.5.0\n",
            "      - scipy==1.13.1\n",
            "      - sentencepiece==0.2.0\n",
            "      - shtab==1.7.1\n",
            "      - six==1.16.0\n",
            "      - snowballstemmer==2.2.0\n",
            "      - spglib==2.4.0\n",
            "      - sympy==1.13.1\n",
            "      - threadpoolctl==3.5.0\n",
            "      - tokenizers==0.19.1\n",
            "      - tomli==2.0.1\n",
            "      - toolz==0.12.1\n",
            "      - torch==2.2.2\n",
            "      - torchdata==0.7.1\n",
            "      - tqdm==4.66.4\n",
            "      - transformers==4.41.2\n",
            "      - triton==2.2.0\n",
            "      - trl==0.8.6\n",
            "      - typing-extensions==4.12.2\n",
            "      - tyro==0.8.4\n",
            "      - tzdata==2024.1\n",
            "      - urllib3==2.2.2\n",
            "      - xformers==0.0.25.post1\n",
            "      - xmltodict==0.13.0\n",
            "      - xxhash==3.4.1\n",
            "      - yarl==1.9.4\n",
            "      - zipp==3.19.2\n",
            "prefix: /usr/local\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnGe03dra32v",
        "outputId": "2c98316b-d257-47de-e99b-a9aa1f771645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accelerate==0.31.0\n",
            "aiohttp==3.9.5\n",
            "aiosignal==1.3.1\n",
            "alignn==2024.4.20\n",
            "annotated-types==0.7.0\n",
            "archspec @ file:///home/conda/feedstock_root/build_artifacts/archspec_1699370045702/work\n",
            "ase==3.23.0\n",
            "async-timeout==4.0.3\n",
            "-e git+https://github.com/usnistgov/atomgpt.git@a516955aa3348e628175d024c6b16896ba34e31a#egg=atomgpt\n",
            "attrs==23.2.0\n",
            "autopep8==2.3.1\n",
            "bitsandbytes==0.43.1\n",
            "black==24.4.2\n",
            "boltons @ file:///home/conda/feedstock_root/build_artifacts/boltons_1703154663129/work\n",
            "Brotli @ file:///home/conda/feedstock_root/build_artifacts/brotli-split_1695989787169/work\n",
            "certifi==2024.6.2\n",
            "cffi @ file:///home/conda/feedstock_root/build_artifacts/cffi_1696001684923/work\n",
            "chardet==3.0.4\n",
            "charset-normalizer @ file:///home/conda/feedstock_root/build_artifacts/charset-normalizer_1698833585322/work\n",
            "click==8.1.7\n",
            "colorama @ file:///home/conda/feedstock_root/build_artifacts/colorama_1666700638685/work\n",
            "conda @ file:///home/conda/feedstock_root/build_artifacts/conda_1701731572133/work\n",
            "conda-libmamba-solver @ file:///home/conda/feedstock_root/build_artifacts/conda-libmamba-solver_1702406360642/work/src\n",
            "conda-package-handling @ file:///home/conda/feedstock_root/build_artifacts/conda-package-handling_1691048088238/work\n",
            "conda_package_streaming @ file:///home/conda/feedstock_root/build_artifacts/conda-package-streaming_1691009212940/work\n",
            "contourpy==1.2.1\n",
            "cycler==0.12.1\n",
            "datasets==2.20.0\n",
            "dgl==1.1.1\n",
            "dill==0.3.8\n",
            "distro @ file:///home/conda/feedstock_root/build_artifacts/distro_1675116244235/work\n",
            "docstring_parser==0.16\n",
            "eval_type_backport==0.2.0\n",
            "filelock==3.15.4\n",
            "flake8==7.1.0\n",
            "fonttools==4.53.0\n",
            "frozenlist==1.4.1\n",
            "fsspec==2024.5.0\n",
            "gmpy2==2.2.1\n",
            "huggingface-hub==0.23.4\n",
            "idna==3.7\n",
            "importlib_resources==6.4.0\n",
            "jarvis-tools==2024.4.30\n",
            "Jinja2==3.1.4\n",
            "joblib==1.4.2\n",
            "jsonpatch @ file:///home/conda/feedstock_root/build_artifacts/jsonpatch_1695536281965/work\n",
            "jsonpointer @ file:///home/conda/feedstock_root/build_artifacts/jsonpointer_1695397238043/work\n",
            "kiwisolver==1.4.5\n",
            "libmambapy @ file:///home/conda/feedstock_root/build_artifacts/mamba-split_1702310393080/work/libmambapy\n",
            "lmdb==1.4.1\n",
            "mamba @ file:///home/conda/feedstock_root/build_artifacts/mamba-split_1702310393080/work/mamba\n",
            "markdown-it-py==3.0.0\n",
            "MarkupSafe==2.1.5\n",
            "matplotlib==3.9.0\n",
            "mccabe==0.7.0\n",
            "mdurl==0.1.2\n",
            "menuinst @ file:///home/conda/feedstock_root/build_artifacts/menuinst_1702317041727/work\n",
            "mpmath==1.3.0\n",
            "multidict==4.7.6\n",
            "multiprocess==0.70.16\n",
            "mypy-extensions==1.0.0\n",
            "networkx==3.3\n",
            "numpy==1.26.4\n",
            "nvidia-cublas-cu12==12.1.3.1\n",
            "nvidia-cuda-cupti-cu12==12.1.105\n",
            "nvidia-cuda-nvrtc-cu12==12.1.105\n",
            "nvidia-cuda-runtime-cu12==12.1.105\n",
            "nvidia-cudnn-cu12==8.9.2.26\n",
            "nvidia-cufft-cu12==11.0.2.54\n",
            "nvidia-curand-cu12==10.3.2.106\n",
            "nvidia-cusolver-cu12==11.4.5.107\n",
            "nvidia-cusparse-cu12==12.1.0.106\n",
            "nvidia-nccl-cu12==2.19.3\n",
            "nvidia-nvjitlink-cu12==12.6.20\n",
            "nvidia-nvtx-cu12==12.1.105\n",
            "packaging==24.1\n",
            "pandas==2.2.2\n",
            "pathspec==0.12.1\n",
            "peft==0.11.1\n",
            "pillow==10.3.0\n",
            "platformdirs==4.2.2\n",
            "pluggy @ file:///home/conda/feedstock_root/build_artifacts/pluggy_1693086607691/work\n",
            "protobuf==5.27.3\n",
            "psutil==6.0.0\n",
            "pyarrow==16.1.0\n",
            "pyarrow-hotfix==0.6\n",
            "pycodestyle==2.12.0\n",
            "pycosat @ file:///home/conda/feedstock_root/build_artifacts/pycosat_1696355758174/work\n",
            "pycparser @ file:///home/conda/feedstock_root/build_artifacts/pycparser_1636257122734/work\n",
            "pydantic==2.7.4\n",
            "pydantic-settings==2.3.3\n",
            "pydantic_core==2.18.4\n",
            "pydocstyle==6.3.0\n",
            "pyflakes==3.2.0\n",
            "Pygments==2.18.0\n",
            "pyparsing==2.4.7\n",
            "PySocks @ file:///home/conda/feedstock_root/build_artifacts/pysocks_1661604839144/work\n",
            "python-dateutil==2.9.0.post0\n",
            "python-dotenv==1.0.1\n",
            "pytz==2024.1\n",
            "PyYAML==6.0.2\n",
            "regex==2024.5.15\n",
            "requests==2.32.3\n",
            "rich==13.7.1\n",
            "ruamel.yaml @ file:///home/conda/feedstock_root/build_artifacts/ruamel.yaml_1699007337104/work\n",
            "ruamel.yaml.clib @ file:///home/conda/feedstock_root/build_artifacts/ruamel.yaml.clib_1695996839082/work\n",
            "safetensors==0.4.3\n",
            "scikit-learn==1.5.0\n",
            "scipy==1.13.1\n",
            "sentencepiece==0.2.0\n",
            "shtab==1.7.1\n",
            "six==1.16.0\n",
            "snowballstemmer==2.2.0\n",
            "spglib==2.4.0\n",
            "sympy==1.13.1\n",
            "threadpoolctl==3.5.0\n",
            "tokenizers==0.19.1\n",
            "tomli==2.0.1\n",
            "toolz==0.12.1\n",
            "torch==2.2.2\n",
            "torchdata==0.7.1\n",
            "tqdm==4.66.4\n",
            "transformers==4.41.2\n",
            "triton==2.2.0\n",
            "trl==0.8.6\n",
            "truststore @ file:///home/conda/feedstock_root/build_artifacts/truststore_1694154605758/work\n",
            "typing_extensions==4.12.2\n",
            "tyro==0.8.4\n",
            "tzdata==2024.1\n",
            "urllib3==2.2.2\n",
            "xformers==0.0.25.post1\n",
            "xmltodict==0.13.0\n",
            "xxhash==3.4.1\n",
            "yarl==1.9.4\n",
            "zipp==3.19.2\n",
            "zstandard==0.22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda env export"
      ],
      "metadata": {
        "id": "zkNYlup4mNHL",
        "outputId": "3e6dd98c-2915-49e2-e674-6946fa172eff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name: base\n",
            "channels:\n",
            "  - conda-forge\n",
            "dependencies:\n",
            "  - _libgcc_mutex=0.1=conda_forge\n",
            "  - _openmp_mutex=4.5=2_gnu\n",
            "  - archspec=0.2.2=pyhd8ed1ab_0\n",
            "  - boltons=23.1.1=pyhd8ed1ab_0\n",
            "  - brotli-python=1.1.0=py310hc6cd4ac_1\n",
            "  - bzip2=1.0.8=hd590300_5\n",
            "  - c-ares=1.24.0=hd590300_0\n",
            "  - ca-certificates=2023.11.17=hbcca054_0\n",
            "  - cffi=1.16.0=py310h2fee648_0\n",
            "  - charset-normalizer=3.3.2=pyhd8ed1ab_0\n",
            "  - colorama=0.4.6=pyhd8ed1ab_0\n",
            "  - conda=23.11.0=py310hff52083_1\n",
            "  - conda-libmamba-solver=23.12.0=pyhd8ed1ab_0\n",
            "  - conda-package-handling=2.2.0=pyh38be061_0\n",
            "  - conda-package-streaming=0.9.0=pyhd8ed1ab_0\n",
            "  - distro=1.8.0=pyhd8ed1ab_0\n",
            "  - fmt=10.1.1=h00ab1b0_1\n",
            "  - icu=73.2=h59595ed_0\n",
            "  - jsonpatch=1.33=pyhd8ed1ab_0\n",
            "  - jsonpointer=2.4=py310hff52083_3\n",
            "  - keyutils=1.6.1=h166bdaf_0\n",
            "  - krb5=1.21.2=h659d440_0\n",
            "  - ld_impl_linux-64=2.40=h41732ed_0\n",
            "  - libarchive=3.7.2=h2aa1ff5_1\n",
            "  - libcurl=8.5.0=hca28451_0\n",
            "  - libedit=3.1.20191231=he28a2e2_2\n",
            "  - libev=4.33=hd590300_2\n",
            "  - libffi=3.4.2=h7f98852_5\n",
            "  - libgcc-ng=13.2.0=h807b86a_3\n",
            "  - libgomp=13.2.0=h807b86a_3\n",
            "  - libiconv=1.17=hd590300_2\n",
            "  - libmamba=1.5.5=had39da4_0\n",
            "  - libmambapy=1.5.5=py310h39ff949_0\n",
            "  - libnghttp2=1.58.0=h47da74e_1\n",
            "  - libnsl=2.0.1=hd590300_0\n",
            "  - libsolv=0.7.27=hfc55251_0\n",
            "  - libsqlite=3.44.2=h2797004_0\n",
            "  - libssh2=1.11.0=h0841786_0\n",
            "  - libstdcxx-ng=13.2.0=h7e041cc_3\n",
            "  - libuuid=2.38.1=h0b41bf4_0\n",
            "  - libxml2=2.12.3=h232c23b_0\n",
            "  - libzlib=1.2.13=hd590300_5\n",
            "  - lz4-c=1.9.4=hcb278e6_0\n",
            "  - lzo=2.10=h516909a_1000\n",
            "  - mamba=1.5.5=py310h51d5547_0\n",
            "  - menuinst=2.0.1=py310hff52083_0\n",
            "  - ncurses=6.4=h59595ed_2\n",
            "  - openssl=3.2.0=hd590300_1\n",
            "  - pip=23.3.2=pyhd8ed1ab_0\n",
            "  - pluggy=1.3.0=pyhd8ed1ab_0\n",
            "  - pybind11-abi=4=hd8ed1ab_3\n",
            "  - pycosat=0.6.6=py310h2372a71_0\n",
            "  - pycparser=2.21=pyhd8ed1ab_0\n",
            "  - pysocks=1.7.1=pyha2e5f31_6\n",
            "  - python=3.10.13=hd12c33a_0_cpython\n",
            "  - python_abi=3.10=4_cp310\n",
            "  - readline=8.2=h8228510_1\n",
            "  - reproc=14.2.4.post0=hd590300_1\n",
            "  - reproc-cpp=14.2.4.post0=h59595ed_1\n",
            "  - ruamel.yaml=0.18.5=py310h2372a71_0\n",
            "  - ruamel.yaml.clib=0.2.7=py310h2372a71_2\n",
            "  - setuptools=68.2.2=pyhd8ed1ab_0\n",
            "  - tk=8.6.13=noxft_h4845f30_101\n",
            "  - truststore=0.8.0=pyhd8ed1ab_0\n",
            "  - wheel=0.42.0=pyhd8ed1ab_0\n",
            "  - xz=5.2.6=h166bdaf_0\n",
            "  - yaml-cpp=0.8.0=h59595ed_0\n",
            "  - zstandard=0.22.0=py310h1275a96_0\n",
            "  - zstd=1.5.5=hfc55251_0\n",
            "  - pip:\n",
            "      - accelerate==0.31.0\n",
            "      - aiohttp==3.9.5\n",
            "      - aiosignal==1.3.1\n",
            "      - alignn==2024.4.20\n",
            "      - annotated-types==0.7.0\n",
            "      - ase==3.23.0\n",
            "      - async-timeout==4.0.3\n",
            "      - attrs==23.2.0\n",
            "      - autopep8==2.3.1\n",
            "      - bitsandbytes==0.43.1\n",
            "      - black==24.4.2\n",
            "      - certifi==2024.6.2\n",
            "      - chardet==3.0.4\n",
            "      - click==8.1.7\n",
            "      - contourpy==1.2.1\n",
            "      - cycler==0.12.1\n",
            "      - datasets==2.20.0\n",
            "      - dgl==1.1.1\n",
            "      - dill==0.3.8\n",
            "      - docstring-parser==0.16\n",
            "      - eval-type-backport==0.2.0\n",
            "      - filelock==3.15.4\n",
            "      - flake8==7.1.0\n",
            "      - fonttools==4.53.0\n",
            "      - frozenlist==1.4.1\n",
            "      - fsspec==2024.5.0\n",
            "      - gmpy2==2.1.5\n",
            "      - huggingface-hub==0.23.4\n",
            "      - idna==3.7\n",
            "      - importlib-resources==6.4.0\n",
            "      - jarvis-tools==2024.4.30\n",
            "      - jinja2==3.1.4\n",
            "      - joblib==1.4.2\n",
            "      - kiwisolver==1.4.5\n",
            "      - lmdb==1.4.1\n",
            "      - markdown-it-py==3.0.0\n",
            "      - markupsafe==2.1.5\n",
            "      - matplotlib==3.9.0\n",
            "      - mccabe==0.7.0\n",
            "      - mdurl==0.1.2\n",
            "      - mpmath==1.3.0\n",
            "      - multidict==4.7.6\n",
            "      - multiprocess==0.70.16\n",
            "      - mypy-extensions==1.0.0\n",
            "      - networkx==3.3\n",
            "      - numpy==1.26.4\n",
            "      - nvidia-cublas-cu12==12.1.3.1\n",
            "      - nvidia-cuda-cupti-cu12==12.1.105\n",
            "      - nvidia-cuda-nvrtc-cu12==12.1.105\n",
            "      - nvidia-cuda-runtime-cu12==12.1.105\n",
            "      - nvidia-cudnn-cu12==8.9.2.26\n",
            "      - nvidia-cufft-cu12==11.0.2.54\n",
            "      - nvidia-curand-cu12==10.3.2.106\n",
            "      - nvidia-cusolver-cu12==11.4.5.107\n",
            "      - nvidia-cusparse-cu12==12.1.0.106\n",
            "      - nvidia-nccl-cu12==2.19.3\n",
            "      - nvidia-nvjitlink-cu12==12.5.40\n",
            "      - nvidia-nvtx-cu12==12.1.105\n",
            "      - packaging==24.1\n",
            "      - pandas==2.2.2\n",
            "      - pathspec==0.12.1\n",
            "      - peft==0.11.1\n",
            "      - pillow==10.3.0\n",
            "      - platformdirs==4.2.2\n",
            "      - psutil==6.0.0\n",
            "      - pyarrow==16.1.0\n",
            "      - pyarrow-hotfix==0.6\n",
            "      - pycodestyle==2.12.0\n",
            "      - pydantic==2.7.4\n",
            "      - pydantic-core==2.18.4\n",
            "      - pydantic-settings==2.3.3\n",
            "      - pydocstyle==6.3.0\n",
            "      - pyflakes==3.2.0\n",
            "      - pygments==2.18.0\n",
            "      - pyparsing==2.4.7\n",
            "      - python-dateutil==2.9.0.post0\n",
            "      - python-dotenv==1.0.1\n",
            "      - pytz==2024.1\n",
            "      - pyyaml==6.0.1\n",
            "      - regex==2024.5.15\n",
            "      - requests==2.32.3\n",
            "      - rich==13.7.1\n",
            "      - safetensors==0.4.3\n",
            "      - scikit-learn==1.5.0\n",
            "      - scipy==1.13.1\n",
            "      - sentencepiece==0.2.0\n",
            "      - shtab==1.7.1\n",
            "      - six==1.16.0\n",
            "      - snowballstemmer==2.2.0\n",
            "      - spglib==2.4.0\n",
            "      - sympy==1.12.1\n",
            "      - threadpoolctl==3.5.0\n",
            "      - tokenizers==0.19.1\n",
            "      - tomli==2.0.1\n",
            "      - toolz==0.12.1\n",
            "      - torch==2.2.2\n",
            "      - torchdata==0.7.1\n",
            "      - tqdm==4.66.4\n",
            "      - transformers==4.41.2\n",
            "      - triton==2.2.0\n",
            "      - trl==0.8.6\n",
            "      - typing-extensions==4.12.2\n",
            "      - tyro==0.8.4\n",
            "      - tzdata==2024.1\n",
            "      - urllib3==2.2.2\n",
            "      - xformers==0.0.25.post1\n",
            "      - xmltodict==0.13.0\n",
            "      - xxhash==3.4.1\n",
            "      - yarl==1.9.4\n",
            "      - zipp==3.19.2\n",
            "prefix: /usr/local\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "opxC-PlXmQtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2cW8QpTombNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# env=\"\"\"name:base\n",
        "# channels:\n",
        "#   - xformers\n",
        "#   - pytorch\n",
        "#   - nvidia\n",
        "#   - conda-forge\n",
        "#   - defaults\n",
        "# dependencies:\n",
        "#   - _libgcc_mutex=0.1=conda_forge\n",
        "#   - _openmp_mutex=4.5=2_gnu\n",
        "#   - blas=1.0=mkl\n",
        "#   - bzip2=1.0.8=h7f98852_4\n",
        "#   - ca-certificates=2024.2.2=hbcca054_0\n",
        "#   - cairo=1.18.0=h3faef2a_0\n",
        "#   - cffi=1.16.0=py39h7a31438_0\n",
        "#   - cuda-cudart=12.1.105=0\n",
        "#   - cuda-cupti=12.1.105=0\n",
        "#   - cuda-libraries=12.1.0=0\n",
        "#   - cuda-nvrtc=12.1.105=0\n",
        "#   - cuda-nvtx=12.1.105=0\n",
        "#   - cuda-opencl=12.4.99=0\n",
        "#   - cuda-runtime=12.1.0=0\n",
        "#   - cudatoolkit=11.7.0=hd8887f6_10\n",
        "#   - expat=2.5.0=hcb278e6_1\n",
        "#   - filelock=3.15.4=pyhd8ed1ab_0\n",
        "#   - font-ttf-dejavu-sans-mono=2.37=hab24e00_0\n",
        "#   - font-ttf-inconsolata=3.000=h77eed37_0\n",
        "#   - font-ttf-source-code-pro=2.038=h77eed37_0\n",
        "#   - font-ttf-ubuntu=0.83=hab24e00_0\n",
        "#   - fontconfig=2.14.2=h14ed4e7_0\n",
        "#   - fonts-conda-ecosystem=1=0\n",
        "#   - fonts-conda-forge=1=0\n",
        "#   - freetype=2.12.1=h267a509_2\n",
        "#   - gettext=0.21.1=h27087fc_0\n",
        "#   - gmp=6.3.0=h59595ed_1\n",
        "#   - gmpy2=2.1.2=py39h376b7d2_1\n",
        "#   - icu=73.2=h59595ed_0\n",
        "#   - intel-openmp=2022.1.0=h9e868ea_3769\n",
        "#   - jinja2=3.1.4=pyhd8ed1ab_0\n",
        "#   - ld_impl_linux-64=2.40=h41732ed_0\n",
        "#   - libblas=3.9.0=16_linux64_mkl\n",
        "#   - libcblas=3.9.0=16_linux64_mkl\n",
        "#   - libcublas=12.1.0.26=0\n",
        "#   - libcufft=11.0.2.4=0\n",
        "#   - libcufile=1.9.0.20=0\n",
        "#   - libcurand=10.3.5.119=0\n",
        "#   - libcusolver=11.4.4.55=0\n",
        "#   - libcusparse=12.0.2.55=0\n",
        "#   - libexpat=2.5.0=hcb278e6_1\n",
        "#   - libffi=3.4.2=h7f98852_5\n",
        "#   - libgcc-ng=13.2.0=h807b86a_2\n",
        "#   - libgfortran-ng=13.2.0=h69a702a_5\n",
        "#   - libgfortran5=13.2.0=ha4646dd_5\n",
        "#   - libglib=2.78.0=hebfc3b9_0\n",
        "#   - libgomp=13.2.0=h807b86a_2\n",
        "#   - libiconv=1.17=h166bdaf_0\n",
        "#   - liblapack=3.9.0=16_linux64_mkl\n",
        "#   - libnpp=12.0.2.50=0\n",
        "#   - libnsl=2.0.0=h7f98852_0\n",
        "#   - libnvjitlink=12.1.105=0\n",
        "#   - libnvjpeg=12.1.1.14=0\n",
        "#   - libopenblas=0.3.26=pthreads_h413a1c8_0\n",
        "#   - libpng=1.6.39=h753d276_0\n",
        "#   - libprotobuf=3.21.12=hfc55251_2\n",
        "#   - libsqlite=3.43.0=h2797004_0\n",
        "#   - libstdcxx-ng=13.2.0=h7e041cc_2\n",
        "#   - libuuid=2.38.1=h0b41bf4_0\n",
        "#   - libxcb=1.15=h0b41bf4_0\n",
        "#   - libxml2=2.11.5=h232c23b_1\n",
        "#   - libzlib=1.2.13=hd590300_5\n",
        "#   - llvm-openmp=15.0.7=h0cdce71_0\n",
        "#   - markupsafe=2.1.5=py39hd1e30aa_0\n",
        "#   - mkl=2022.1.0=hc2b9512_224\n",
        "#   - mpc=1.3.1=hfe3b2da_0\n",
        "#   - mpfr=4.2.1=h9458935_0\n",
        "#   - mpmath=1.3.0=pyhd8ed1ab_0\n",
        "#   - ncurses=6.4=hcb278e6_0\n",
        "#   - networkx=3.2.1=pyhd8ed1ab_0\n",
        "#   - ninja=1.11.1=h924138e_0\n",
        "#   - openbabel=3.1.1=py39h421517d_8\n",
        "#   - openssl=3.2.1=hd590300_1\n",
        "#   - pcre2=10.40=hc3806b6_0\n",
        "#   - pip=23.2.1=pyhd8ed1ab_0\n",
        "#   - pixman=0.42.2=h59595ed_0\n",
        "#   - pthread-stubs=0.4=h36c2ea0_1001\n",
        "#   - pycparser=2.22=pyhd8ed1ab_0\n",
        "#   - python=3.9.18=h0755675_0_cpython\n",
        "#   - python_abi=3.9=4_cp39\n",
        "#   - pytorch=2.2.2=py3.9_cuda12.1_cudnn8.9.2_0\n",
        "#   - pytorch-cuda=12.1=ha16c6d3_5\n",
        "#   - pytorch-mutex=1.0=cuda\n",
        "#   - pyyaml=6.0.1=py39hd1e30aa_1\n",
        "#   - readline=8.2=h8228510_1\n",
        "#   - setuptools=68.2.2=pyhd8ed1ab_0\n",
        "#   - sleef=3.5.1=h9b69904_2\n",
        "#   - sympy=1.12=pypyh9d50eac_103\n",
        "#   - tk=8.6.13=h2797004_0\n",
        "#   - torchtriton=2.2.0=py39\n",
        "#   - typing_extensions=4.10.0=pyha770c72_0\n",
        "#   - wheel=0.43.0=pyhd8ed1ab_1\n",
        "#   - xformers=0.0.25.post1=py39_cu12.1.0_pyt2.2.2\n",
        "#   - xorg-kbproto=1.0.7=h7f98852_1002\n",
        "#   - xorg-libice=1.1.1=hd590300_0\n",
        "#   - xorg-libsm=1.2.4=h7391055_0\n",
        "#   - xorg-libx11=1.8.7=h8ee46fc_0\n",
        "#   - xorg-libxau=1.0.11=hd590300_0\n",
        "#   - xorg-libxdmcp=1.1.3=h7f98852_0\n",
        "#   - xorg-libxext=1.3.4=h0b41bf4_2\n",
        "#   - xorg-libxrender=0.9.11=hd590300_0\n",
        "#   - xorg-renderproto=0.11.1=h7f98852_1002\n",
        "#   - xorg-xextproto=7.3.0=h0b41bf4_1003\n",
        "#   - xorg-xproto=7.0.31=h7f98852_1007\n",
        "#   - xz=5.2.6=h166bdaf_0\n",
        "#   - yaml=0.2.5=h7f98852_2\n",
        "#   - zlib=1.2.13=hd590300_5\n",
        "#   - pip:\n",
        "#       - accelerate==0.31.0\n",
        "#       - aiohttp==3.9.5\n",
        "#       - aiosignal==1.3.1\n",
        "#       - alignn==2024.4.20\n",
        "#       - annotated-types==0.7.0\n",
        "#       - ase==3.23.0\n",
        "#       - async-timeout==4.0.3\n",
        "#       - attrs==23.2.0\n",
        "#       - autopep8==2.3.1\n",
        "#       - bitsandbytes==0.43.1\n",
        "#       - black==24.4.2\n",
        "#       - certifi==2024.6.2\n",
        "#       - chardet==3.0.4\n",
        "#       - charset-normalizer==3.3.2\n",
        "#       - click==8.1.7\n",
        "#       - contourpy==1.2.1\n",
        "#       - cycler==0.12.1\n",
        "#       - datasets==2.20.0\n",
        "#       - dgl==1.1.1\n",
        "#       - dill==0.3.8\n",
        "#       - docstring-parser==0.16\n",
        "#       - eval-type-backport==0.2.0\n",
        "#       - flake8==7.1.0\n",
        "#       - fonttools==4.53.0\n",
        "#       - frozenlist==1.4.1\n",
        "#       - fsspec==2024.5.0\n",
        "#       - huggingface-hub==0.23.4\n",
        "#       - idna==3.7\n",
        "#       - importlib-resources==6.4.0\n",
        "#       - jarvis-tools==2024.4.30\n",
        "#       - joblib==1.4.2\n",
        "#       - kiwisolver==1.4.5\n",
        "#       - lmdb==1.4.1\n",
        "#       - markdown-it-py==3.0.0\n",
        "#       - matplotlib==3.9.0\n",
        "#       - mccabe==0.7.0\n",
        "#       - mdurl==0.1.2\n",
        "#       - multidict==4.7.6\n",
        "#       - multiprocess==0.70.16\n",
        "#       - mypy-extensions==1.0.0\n",
        "#       - numpy==1.26.4\n",
        "#       - packaging==24.1\n",
        "#       - pandas==2.2.2\n",
        "#       - pathspec==0.12.1\n",
        "#       - peft==0.11.1\n",
        "#       - pillow==10.3.0\n",
        "#       - platformdirs==4.2.2\n",
        "#       - psutil==6.0.0\n",
        "#       - pyarrow==16.1.0\n",
        "#       - pyarrow-hotfix==0.6\n",
        "#       - pycodestyle==2.12.0\n",
        "#       - pydantic==2.7.4\n",
        "#       - pydantic-core==2.18.4\n",
        "#       - pydantic-settings==2.3.3\n",
        "#       - pydocstyle==6.3.0\n",
        "#       - pyflakes==3.2.0\n",
        "#       - pygments==2.18.0\n",
        "#       - pyparsing==2.4.7\n",
        "#       - python-dateutil==2.9.0.post0\n",
        "#       - python-dotenv==1.0.1\n",
        "#       - pytz==2024.1\n",
        "#       - regex==2024.5.15\n",
        "#       - requests==2.32.3\n",
        "#       - rich==13.7.1\n",
        "#       - safetensors==0.4.3\n",
        "#       - scikit-learn==1.5.0\n",
        "#       - scipy==1.13.1\n",
        "#       - sentencepiece==0.2.0\n",
        "#       - shtab==1.7.1\n",
        "#       - six==1.16.0\n",
        "#       - snowballstemmer==2.2.0\n",
        "#       - spglib==2.4.0\n",
        "#       - threadpoolctl==3.5.0\n",
        "#       - tokenizers==0.19.1\n",
        "#       - tomli==2.0.1\n",
        "#       - toolz==0.12.1\n",
        "#       - torchdata==0.7.1\n",
        "#       - tqdm==4.66.4\n",
        "#       - transformers==4.41.2\n",
        "#       - trl==0.8.6\n",
        "#       - tyro==0.8.4\n",
        "#       - tzdata==2024.1\n",
        "#       - urllib3==2.2.2\n",
        "#       - xmltodict==0.13.0\n",
        "#       - xxhash==3.4.1\n",
        "#       - yarl==1.9.4\n",
        "#       - zipp==3.19.2\n",
        "# \"\"\"\n",
        "# with open(f'/content/conda.yaml', 'w') as f:\n",
        "#     f.write(env)\n",
        "# # !conda env update --name base -f conda.yaml"
      ],
      "metadata": {
        "id": "jvEq4Wu0mbPp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}