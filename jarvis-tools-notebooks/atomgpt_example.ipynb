{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/knc6/jarvis-tools-notebooks/blob/master/jarvis-tools-notebooks/atomgpt_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AtomGPT example: https://pubs.acs.org/doi/10.1021/acs.jpclett.4c01126\n"
      ],
      "metadata": {
        "id": "TkkuV4Hyib2K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Table of contents\n",
        "\n",
        "1. Installing [AtomGPT](https://github.com/usnistgov/atomgpt)\n",
        "2. Example inverse model training for 5 materials\n",
        "3. Using the trained model for inference\n",
        "4. Relaxing structures with ALIGNN-FF\n",
        "5. Generating a database of atomic structures\n",
        "\n",
        "\n",
        "Author: Kamal Choudhary (kamal.choudhary@nist.gov)"
      ],
      "metadata": {
        "id": "bhdCyKO2tSeu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HURIAsbZgMF",
        "outputId": "5ecc6527-f819-42f3-a868-4b7f23d2d47c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏬ Downloading https://github.com/jaimergp/miniforge/releases/download/24.11.2-1_colab/Miniforge3-colab-24.11.2-1_colab-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:13\n",
            "🔁 Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "# !pip install -q condacolab\n",
        "# import condacolab\n",
        "# condacolab.install()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation"
      ],
      "metadata": {
        "id": "ZfBX7ilpiouF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import os\n",
        "os.chdir('/content')\n",
        "!rm -rf Software\n",
        "os.makedirs('/content/Software')\n",
        "os.chdir('/content/Software')\n",
        "if not os.path.exists('atomgpt'):\n",
        "  !rm -rf atomgpt\n",
        "  !git clone https://github.com/atomgptlab/atomgpt.git\n",
        "  !git checkout develop\n",
        "  os.chdir('atomgpt')\n",
        "  !pip install -q -e .\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLbIamvfsqHm",
        "outputId": "6228bde6-c73a-4316-ff05-15d9b48c1dbe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'atomgpt'...\n",
            "remote: Enumerating objects: 1348, done.\u001b[K\n",
            "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 1348 (delta 54), reused 52 (delta 49), pack-reused 1282 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1348/1348), 67.15 MiB | 23.26 MiB/s, done.\n",
            "Resolving deltas: 100% (766/766), done.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.5/104.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m344.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.2/67.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.4/72.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.1/362.1 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.6/159.6 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.4/94.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.3/509.3 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m134.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.7/223.7 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m119.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.5/232.5 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.2/444.2 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.2/243.2 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.0/809.0 kB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.5/226.5 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m124.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.5/31.5 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.1/358.1 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\n",
            "langchain-core 0.3.67 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
            "ibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 20.0.0 which is incompatible.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\n",
            "pylibcudf-cu12 25.2.1 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 20.0.0 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCPU times: user 2.92 s, sys: 954 ms, total: 3.87 s\n",
            "Wall time: 4min 29s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q jarvis_leaderboard"
      ],
      "metadata": {
        "id": "5s-xshg4Ksls",
        "outputId": "5a748780-8283-4ed1-88ce-38ff5c1f2e2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.1/72.1 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "textblob 0.19.0 requires nltk>=3.9, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check import\n",
        "import atomgpt\n",
        "import os\n",
        "os.environ.pop('MPLBACKEND', None)  # Remove the invalid backend\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')  # Use a compatible backend\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "metadata": {
        "id": "A57B4HSIKsiJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!jarvis_populate_data.py --benchmark_file AI-SinglePropertyPrediction-exfoliation_energy-dft_3d-test-mae --output_path=Out"
      ],
      "metadata": {
        "id": "PJCSrGz9KwqU",
        "outputId": "992c2c8d-2853-4c4f-963a-a7b0aaa76f75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "benchmark_file AI-SinglePropertyPrediction-exfoliation_energy-dft_3d-test-mae\n",
            "dataset dft_3d\n",
            "output_path Out\n",
            "property exfoliation_energy\n",
            "method AI\n",
            "task SinglePropertyPrediction\n",
            "id_tag jid\n",
            "out_format poscar\n",
            "dataset file to be used /usr/local/lib/python3.11/dist-packages/jarvis_leaderboard/benchmarks/AI/SinglePropertyPrediction/dft_3d_exfoliation_energy.json.zip\n",
            "Currently for atomistic datasets only.\n",
            "https://jarvis-tools.readthedocs.io/en/master/databases.html\n",
            "Obtaining 3D dataset 76k ...\n",
            "Reference:https://www.nature.com/articles/s41524-020-00440-1\n",
            "Other versions:https://doi.org/10.6084/m9.figshare.6815699\n",
            "100% 40.8M/40.8M [00:03<00:00, 12.4MiB/s]\n",
            "Loading the zipfile...\n",
            "Loading completed.\n",
            "number of training samples 650\n",
            "number of validation samples 81\n",
            "number of test samples 81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jarvis.db.jsonutils import loadjson,dumpjson\n",
        "dataset_info = loadjson('Out/dataset_info.json')\n",
        "#print(dataset_info)\n",
        "n_train = dataset_info['n_train']\n",
        "n_val = dataset_info['n_val']\n",
        "n_test = dataset_info['n_test']"
      ],
      "metadata": {
        "id": "yzy3HXrrKwne"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_config={'id_prop_path': \"Out/id_prop.csv\",\n",
        " 'prefix': 'atomgpt_run',\n",
        " 'model_name': \"knc6/atomgpt_mistral_tc_supercon\",\n",
        " 'batch_size': 2,\n",
        " 'num_epochs': 5,\n",
        " 'seed_val': 42,\n",
        " 'num_train': 2,\n",
        " 'num_test': 2,\n",
        " 'model_save_path': 'lora_model_m'}\n",
        "dumpjson(data=temp_config,filename='atomgpt_inverse_config.json')"
      ],
      "metadata": {
        "id": "iBA_lyw7LjEi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "qa7fheaiLYgp",
        "outputId": "4d9e3041-c2d1-49cd-d1ed-f1ffdd811f8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Software/atomgpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install triton==3.2.0"
      ],
      "metadata": {
        "id": "y2Cmxar4hJFV",
        "outputId": "76d4249d-af24-485c-ad91-7bda4f54331e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting triton==3.2.0\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.3.0\n",
            "    Uninstalling triton-3.3.0:\n",
            "      Successfully uninstalled triton-3.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.7.0 requires triton==3.3.0; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have triton 3.2.0 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\n",
            "atomgpt 2025.6.7 requires triton==3.3.0, but you have triton 3.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed triton-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import triton\n",
        "triton.__version__"
      ],
      "metadata": {
        "id": "CaNkjayXhWl5",
        "outputId": "764314b9-1ffa-4ed3-96fb-8e13fe47425a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.2.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "export WANDB_MODE=offline"
      ],
      "metadata": {
        "id": "ZU-4VSgxh-HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python atomgpt/inverse_models/inverse_models.py --config_name atomgpt/examples/inverse_model/config.json"
      ],
      "metadata": {
        "id": "IgCR8akGgLyM",
        "outputId": "800afce5-d42d-48bb-beb2-bd5b0fd42887",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-07-09 04:50:53.802864: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1752036653.841990    4389 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1752036653.853035    4389 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-09 04:50:53.891604: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "         _                   _____ _____ _______ \n",
            "    /\\  | |                 / ____|  __ \\__   __|\n",
            "   /  \\ | |_ ___  _ __ ___ | |  __| |__) | | |   \n",
            "  / /\\ \\| __/ _ \\| '_ ` _ \\| | |_ |  ___/  | |   \n",
            " / ____ \\ || (_) | | | | | | |__| | |      | |   \n",
            "/_/    \\_\\__\\___/|_| |_| |_|\\_____|_|      |_|   \n",
            "   \n",
            "config_file atomgpt/examples/inverse_model/config.json\n",
            "/content/Software/atomgpt/atomgpt/inverse_models/inverse_models.py:343: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
            "  pprint.pprint(config.dict())\n",
            "{'alpaca_prompt': '### Instruction:\\n{}\\n### Input:\\n{}\\n### Output:\\n{}',\n",
            " 'batch_size': 2,\n",
            " 'callback_samples': 2,\n",
            " 'chem_info': 'formula',\n",
            " 'csv_out': 'AI-AtomGen-prop-dft_3d-test-rmse.csv',\n",
            " 'dataset_num_proc': 2,\n",
            " 'dtype': None,\n",
            " 'file_format': 'poscar',\n",
            " 'gradient_accumulation_steps': 4,\n",
            " 'id_prop_path': 'atomgpt/examples/inverse_model/id_prop.csv',\n",
            " 'id_tag': 'id',\n",
            " 'instruction': 'Below is a description of a superconductor material.',\n",
            " 'learning_rate': 0.0002,\n",
            " 'load_in_4bit': True,\n",
            " 'logging_steps': 1,\n",
            " 'lora_alpha': 16,\n",
            " 'lora_rank': 16,\n",
            " 'loss_type': 'default',\n",
            " 'lr_scheduler_type': 'linear',\n",
            " 'max_seq_length': 2048,\n",
            " 'model_name': 'knc6/atomgpt_mistral_tc_supercon',\n",
            " 'model_save_path': 'lora_model_m',\n",
            " 'num_epochs': 2,\n",
            " 'num_test': None,\n",
            " 'num_train': None,\n",
            " 'optim': 'adamw_8bit',\n",
            " 'output_dir': 'outputs',\n",
            " 'output_prompt': ' Generate atomic structure description with lattice '\n",
            "                  'lengths, angles, coordinates and atom types.',\n",
            " 'per_device_train_batch_size': 2,\n",
            " 'prefix': 'atomgpt_run',\n",
            " 'prop': 'Tc_supercon',\n",
            " 'save_steps': 2,\n",
            " 'save_strategy': 'steps',\n",
            " 'seed_val': 3407,\n",
            " 'separator': ',',\n",
            " 'test_ratio': 0.3}\n",
            "/content/Software/atomgpt/atomgpt/inverse_models/inverse_models.py:348: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
            "  tmp = config.dict()\n",
            "100% 10/10 [00:00<00:00, 899.52it/s]\n",
            "num_train 7\n",
            "num_test 3\n",
            "outputs/alpaca_prop_train.json  exists\n",
            "Sample:\n",
            " {'instruction': 'Below is a description of a superconductor material.', 'input': 'The chemical formula is MgB2 . The  Tc_supercon is 33.0. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.', 'output': '3.07 3.07 3.51\\n90 90 119\\nMg 0.000 0.000 0.000\\nB 0.667 0.333 0.500\\nB 0.333 0.667 0.500'}\n",
            "outputs/alpaca_prop_test.json exists\n",
            "AtomGPT 2025.5.7: Fast Mistral patching. Transformers: 4.51.3.\n",
            "Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "Torch: 2.7.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.2.0\n",
            "Bfloat16 = FALSE. FA [Xformers = 0.0.30. FA2 = False]\n",
            "\n",
            "AtomGPT 2025.5.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n",
            "🧠 Suggested max_seq_length based on dataset: 111\n",
            "/usr/local/lib/python3.11/dist-packages/dill/_dill.py:414: PicklingWarning: Cannot locate reference to <class '__main__.TrainingPropConfig'>.\n",
            "  StockPickler.save(self, obj, save_persistent_id)\n",
            "/usr/local/lib/python3.11/dist-packages/dill/_dill.py:414: PicklingWarning: Cannot pickle <class '__main__.TrainingPropConfig'>: __main__.TrainingPropConfig has recursive self-references that trigger a RecursionError.\n",
            "  StockPickler.save(self, obj, save_persistent_id)\n",
            "Map: 100% 10/10 [00:00<00:00, 164.89 examples/s]\n",
            "Map: 100% 5/5 [00:00<00:00, 328.05 examples/s]\n",
            "AtomGPT - 2x faster free finetuning | Num GPUs used = 1\n",
            "Num examples = 10 | Num Epochs = 2 | Total steps = 2\n",
            "Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            "Trainable parameters = 41,943,040/7,000,000,000 (0.60% trained)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "  0% 0/2 [00:00<?, ?it/s]AtomGPT: Will smartly offload gradients to save VRAM!\n",
            " 50% 1/2 [00:51<00:51, 51.27s/it]\n",
            "🔹 Sample 0\n",
            "generated_text ### Instruction: Below is a description of a superconductor material. ### Input: The chemical formula is Ta . The  Tc_supercon is 7.6. Generate atomic structure description with lattice lengths, angles, coordinates and atom types. ### Output: 3.28 4.26 4.68 90 90 90 Ta 0.000 0.750 0.292 Ta 0.500 0.250 0.708 Ta 0.000 0.250 0.708 Ta 0.500 0.750 0.292\n",
            "🔸 Target   :\n",
            "System\n",
            "1.0\n",
            "2.71364 0.0 -0.93438\n",
            "-1.30995 2.37652 -0.93438\n",
            "0.0 0.0 2.87\n",
            "Ta \n",
            "1 \n",
            "direct\n",
            "0.0 0.0 -0.0 Ta\n",
            "\n",
            "🔸 Predicted:\n",
            "System\n",
            "1.0\n",
            "3.28 0.0 0.0\n",
            "0.0 4.26 0.0\n",
            "0.0 0.0 4.68\n",
            "Ta \n",
            "4 \n",
            "direct\n",
            "0.0 0.75 0.292 Ta\n",
            "0.5 0.25 0.708 Ta\n",
            "0.0 0.25 0.708 Ta\n",
            "0.5 0.75 0.292 Ta\n",
            "\n",
            "\n",
            "🔹 Sample 1\n",
            "generated_text ### Instruction: Below is a description of a superconductor material. ### Input: The chemical formula is Ta . The  Tc_supercon is 7.6. Generate atomic structure description with lattice lengths, angles, coordinates and atom types. ### Output: 3.28 4.26 4.68 90 90 90 Ta 0.000 0.750 0.292 Ta 0.500 0.250 0.708 Ta 0.000 0.250 0.708 Ta 0.500 0.750 0.292\n",
            "🔸 Target   :\n",
            "System\n",
            "1.0\n",
            "2.71364 0.0 -0.93438\n",
            "-1.30995 2.37652 -0.93438\n",
            "0.0 0.0 2.87\n",
            "Ta \n",
            "1 \n",
            "direct\n",
            "0.0 0.0 -0.0 Ta\n",
            "\n",
            "🔸 Predicted:\n",
            "System\n",
            "1.0\n",
            "3.28 0.0 0.0\n",
            "0.0 4.26 0.0\n",
            "0.0 0.0 4.68\n",
            "Ta \n",
            "4 \n",
            "direct\n",
            "0.0 0.75 0.292 Ta\n",
            "0.5 0.25 0.708 Ta\n",
            "0.0 0.25 0.708 Ta\n",
            "0.5 0.75 0.292 Ta\n",
            "\n",
            "Wed Jul  9 04:52:46 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   72C    P0             39W /   70W |    7680MiB /  15360MiB |     81%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "{'loss': 1.1064, 'grad_norm': 6.470474720001221, 'learning_rate': 0.0, 'epoch': 0.8}\n",
            "100% 2/2 [01:15<00:00, 35.20s/it]\n",
            "🔹 Sample 0\n",
            "generated_text ### Instruction: Below is a description of a superconductor material. ### Input: The chemical formula is Ta . The  Tc_supercon is 7.6. Generate atomic structure description with lattice lengths, angles, coordinates and atom types. ### Output: 3.28 3.28 4.91 90 90 119 Ta 0.000 0.000 0.000 Ta 0.000 0.000 0.500\n",
            "🔸 Target   :\n",
            "System\n",
            "1.0\n",
            "2.71364 0.0 -0.93438\n",
            "-1.30995 2.37652 -0.93438\n",
            "0.0 0.0 2.87\n",
            "Ta \n",
            "1 \n",
            "direct\n",
            "0.0 0.0 -0.0 Ta\n",
            "\n",
            "🔸 Predicted:\n",
            "System\n",
            "1.0\n",
            "3.28 0.0 0.0\n",
            "-1.59018 2.86875 0.0\n",
            "0.0 0.0 4.91\n",
            "Ta \n",
            "2 \n",
            "direct\n",
            "0.0 0.0 0.0 Ta\n",
            "0.0 0.0 0.5 Ta\n",
            "\n",
            "\n",
            "🔹 Sample 1\n",
            "generated_text ### Instruction: Below is a description of a superconductor material. ### Input: The chemical formula is Ta . The  Tc_supercon is 7.6. Generate atomic structure description with lattice lengths, angles, coordinates and atom types. ### Output: 3.28 3.28 4.91 90 90 119 Ta 0.000 0.000 0.000 Ta 0.000 0.000 0.500\n",
            "🔸 Target   :\n",
            "System\n",
            "1.0\n",
            "2.71364 0.0 -0.93438\n",
            "-1.30995 2.37652 -0.93438\n",
            "0.0 0.0 2.87\n",
            "Ta \n",
            "1 \n",
            "direct\n",
            "0.0 0.0 -0.0 Ta\n",
            "\n",
            "🔸 Predicted:\n",
            "System\n",
            "1.0\n",
            "3.28 0.0 0.0\n",
            "-1.59018 2.86875 0.0\n",
            "0.0 0.0 4.91\n",
            "Ta \n",
            "2 \n",
            "direct\n",
            "0.0 0.0 0.0 Ta\n",
            "0.0 0.0 0.5 Ta\n",
            "\n",
            "Wed Jul  9 04:53:05 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   76C    P0             67W /   70W |    8332MiB /  15360MiB |     76%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "{'loss': 0.9771, 'grad_norm': 5.5124406814575195, 'learning_rate': 1e-05, 'epoch': 1.0}\n",
            "{'train_runtime': 90.8937, 'train_samples_per_second': 0.22, 'train_steps_per_second': 0.022, 'train_loss': 1.0417492389678955, 'epoch': 1.0}\n",
            "100% 2/2 [01:25<00:00, 42.79s/it]\n",
            "Testing\n",
            " 5\n",
            "  0% 0/5 [00:00<?, ?it/s]target_mat System\n",
            "1.0\n",
            "2.71364 0.0 -0.93438\n",
            "-1.30995 2.37652 -0.93438\n",
            "0.0 0.0 2.87\n",
            "Ta \n",
            "1 \n",
            "direct\n",
            "0.0 0.0 -0.0 Ta\n",
            "\n",
            "genmat System\n",
            "1.0\n",
            "3.28 0.0 0.0\n",
            "-1.59018 2.86875 0.0\n",
            "0.0 0.0 4.91\n",
            "Ta \n",
            "2 \n",
            "direct\n",
            "0.0 0.0 0.0 Ta\n",
            "0.0 0.0 0.5 Ta\n",
            "\n",
            " 20% 1/5 [00:04<00:16,  4.22s/it]target_mat System\n",
            "1.0\n",
            "2.71364 0.0 -0.93438\n",
            "-1.30995 2.37652 -0.93438\n",
            "0.0 0.0 2.87\n",
            "Ta \n",
            "1 \n",
            "direct\n",
            "0.0 0.0 -0.0 Ta\n",
            "\n",
            "genmat System\n",
            "1.0\n",
            "3.28 0.0 0.0\n",
            "-1.59018 2.86875 0.0\n",
            "0.0 0.0 4.91\n",
            "Ta \n",
            "2 \n",
            "direct\n",
            "0.0 0.0 0.0 Ta\n",
            "0.0 0.0 0.5 Ta\n",
            "\n",
            " 40% 2/5 [00:09<00:14,  4.96s/it]target_mat System\n",
            "1.0\n",
            "2.71364 0.0 -0.93438\n",
            "-1.30995 2.37652 -0.93438\n",
            "0.0 0.0 2.87\n",
            "Ta \n",
            "1 \n",
            "direct\n",
            "0.0 0.0 -0.0 Ta\n",
            "\n",
            "genmat System\n",
            "1.0\n",
            "3.28 0.0 0.0\n",
            "-1.59018 2.86875 0.0\n",
            "0.0 0.0 4.91\n",
            "Ta \n",
            "2 \n",
            "direct\n",
            "0.0 0.0 0.0 Ta\n",
            "0.0 0.0 0.5 Ta\n",
            "\n",
            " 60% 3/5 [00:15<00:10,  5.17s/it]target_mat System\n",
            "1.0\n",
            "2.71364 0.0 -0.93438\n",
            "-1.30995 2.37652 -0.93438\n",
            "0.0 0.0 2.87\n",
            "Ta \n",
            "1 \n",
            "direct\n",
            "0.0 0.0 -0.0 Ta\n",
            "\n",
            "genmat System\n",
            "1.0\n",
            "3.28 0.0 0.0\n",
            "-1.59018 2.86875 0.0\n",
            "0.0 0.0 4.91\n",
            "Ta \n",
            "2 \n",
            "direct\n",
            "0.0 0.0 0.0 Ta\n",
            "0.0 0.0 0.5 Ta\n",
            "\n",
            " 80% 4/5 [00:19<00:04,  4.79s/it]target_mat System\n",
            "1.0\n",
            "2.71364 0.0 -0.93438\n",
            "-1.30995 2.37652 -0.93438\n",
            "0.0 0.0 2.87\n",
            "Ta \n",
            "1 \n",
            "direct\n",
            "0.0 0.0 -0.0 Ta\n",
            "\n",
            "genmat System\n",
            "1.0\n",
            "3.28 0.0 0.0\n",
            "-1.59018 2.86875 0.0\n",
            "0.0 0.0 4.91\n",
            "Ta \n",
            "2 \n",
            "direct\n",
            "0.0 0.0 0.0 Ta\n",
            "0.0 0.0 0.5 Ta\n",
            "\n",
            "100% 5/5 [00:23<00:00,  4.76s/it]\n",
            "Time taken: 141.02412128448486\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/Software/atomgpt/wandb/offline-run-20250709_045139-fgayok9p\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20250709_045139-fgayok9p/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!atomgpt_inverse_train --config_name atomgpt_inverse_config.json"
      ],
      "metadata": {
        "id": "WOZMra5rKwig",
        "outputId": "8481f1bf-bb81-4113-8bf2-ab6e5fdf6fdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_save_path\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "\n",
            "         _                   _____ _____ _______ \n",
            "    /\\  | |                 / ____|  __ \\__   __|\n",
            "   /  \\ | |_ ___  _ __ ___ | |  __| |__) | | |   \n",
            "  / /\\ \\| __/ _ \\| '_ ` _ \\| | |_ |  ___/  | |   \n",
            " / ____ \\ || (_) | | | | | | |__| | |      | |   \n",
            "/_/    \\_\\__\\___/|_| |_| |_|\\_____|_|      |_|   \n",
            "   \n",
            "config_file atomgpt_inverse_config.json\n",
            "{'alpaca_prompt': '### Instruction:\\n{}\\n### Input:\\n{}\\n### Output:\\n{}',\n",
            " 'batch_size': 2,\n",
            " 'chem_info': 'formula',\n",
            " 'csv_out': 'AI-AtomGen-prop-dft_3d-test-rmse.csv',\n",
            " 'dataset_num_proc': 2,\n",
            " 'dtype': None,\n",
            " 'file_format': 'poscar',\n",
            " 'gradient_accumulation_steps': 4,\n",
            " 'id_prop_path': 'Out/id_prop.csv',\n",
            " 'id_tag': 'id',\n",
            " 'instruction': 'Below is a description of a superconductor material.',\n",
            " 'learning_rate': 0.0002,\n",
            " 'load_in_4bit': True,\n",
            " 'logging_steps': 1,\n",
            " 'loss_type': 'default',\n",
            " 'lr_scheduler_type': 'linear',\n",
            " 'max_seq_length': 2048,\n",
            " 'model_name': 'knc6/atomgpt_mistral_tc_supercon',\n",
            " 'model_save_path': 'lora_model_m',\n",
            " 'num_epochs': 5,\n",
            " 'num_test': 2,\n",
            " 'num_train': 2,\n",
            " 'num_val': 2,\n",
            " 'optim': 'adamw_8bit',\n",
            " 'output_dir': 'outputs',\n",
            " 'output_prompt': ' Generate atomic structure description with lattice '\n",
            "                  'lengths, angles, coordinates and atom types.',\n",
            " 'per_device_train_batch_size': 2,\n",
            " 'prefix': 'atomgpt_run',\n",
            " 'prop': 'Tc_supercon',\n",
            " 'seed_val': 42}\n",
            "100% 812/812 [00:00<00:00, 5486.04it/s]\n",
            "config.prop Tc_supercon\n",
            "Sample:\n",
            " {'instruction': 'Below is a description of a superconductor material.', 'input': 'The chemical formula is NaZnP . The  Tc_supercon is 124.8. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.', 'output': '4.07 4.07 6.89\\n90 90 90\\nNa 0.000 0.500 0.644\\nNa 0.500 0.000 0.356\\nZn 0.000 0.000 0.000\\nZn 0.500 0.500 0.000\\nP 0.500 0.000 0.785\\nP 0.000 0.500 0.215'}\n",
            "config.prop Tc_supercon\n",
            "adapter_config.json: 100% 732/732 [00:00<00:00, 4.75MB/s]\n",
            "config.json: 100% 1.19k/1.19k [00:00<00:00, 7.85MB/s]\n",
            "   GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\n",
            "   Pytorch: 2.2.2+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "  Bfloat16 = FALSE. Xformers = 0.0.25.post1. FA = False.\n",
            "\n",
            "model.safetensors: 100% 4.13G/4.13G [00:29<00:00, 140MB/s] \n",
            "generation_config.json: 100% 155/155 [00:00<00:00, 1.17MB/s]\n",
            "tokenizer_config.json: 100% 1.02k/1.02k [00:00<00:00, 7.89MB/s]\n",
            "tokenizer.model: 100% 493k/493k [00:00<00:00, 6.49MB/s]\n",
            "special_tokens_map.json: 100% 438/438 [00:00<00:00, 3.26MB/s]\n",
            "tokenizer.json: 100% 1.80M/1.80M [00:00<00:00, 2.68MB/s]\n",
            "adapter_model.safetensors: 100% 168M/168M [00:01<00:00, 157MB/s]\n",
            "Unsloth 2024.5 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n",
            "Generating train split: 2 examples [00:00, 22.55 examples/s]\n",
            "Map: 100% 2/2 [00:00<00:00, 405.97 examples/s]\n",
            "Map (num_proc=2): 100% 2/2 [00:00<00:00,  5.30 examples/s]\n",
            "/usr/local/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
            "  warnings.warn(\n",
            "Num GPUs = 1\n",
            "Num examples = 2 | Num Epochs = 5\n",
            "Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "Total batch size = 8 | Total steps = 5\n",
            "Number of trainable parameters = 41,943,040\n",
            "{'loss': 0.3134, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 1.0}\n",
            "{'loss': 0.3134, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 2.0}\n",
            "{'loss': 0.3134, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 3.0}\n",
            "{'loss': 0.3134, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 4.0}\n",
            "{'loss': 0.3134, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 5.0}\n",
            "{'train_runtime': 15.0322, 'train_samples_per_second': 0.665, 'train_steps_per_second': 0.333, 'train_loss': 0.31335602402687074, 'epoch': 5.0}\n",
            "100% 5/5 [00:15<00:00,  3.01s/it]\n",
            "   GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\n",
            "   Pytorch: 2.2.2+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "  Bfloat16 = FALSE. Xformers = 0.0.25.post1. FA = False.\n",
            "\n",
            "{'alpaca_prompt': '### Instruction:\\n{}\\n### Input:\\n{}\\n### Output:\\n{}',\n",
            " 'batch_size': 2,\n",
            " 'chem_info': 'formula',\n",
            " 'csv_out': 'AI-AtomGen-prop-dft_3d-test-rmse.csv',\n",
            " 'dataset_num_proc': 2,\n",
            " 'dtype': None,\n",
            " 'file_format': 'poscar',\n",
            " 'gradient_accumulation_steps': 4,\n",
            " 'id_prop_path': 'Out/id_prop.csv',\n",
            " 'id_tag': 'id',\n",
            " 'instruction': 'Below is a description of a superconductor material.',\n",
            " 'learning_rate': 0.0002,\n",
            " 'load_in_4bit': True,\n",
            " 'logging_steps': 1,\n",
            " 'loss_type': 'default',\n",
            " 'lr_scheduler_type': 'linear',\n",
            " 'max_seq_length': 2048,\n",
            " 'model_name': 'knc6/atomgpt_mistral_tc_supercon',\n",
            " 'model_save_path': 'lora_model_m',\n",
            " 'num_epochs': 5,\n",
            " 'num_test': 2,\n",
            " 'num_train': 2,\n",
            " 'num_val': 2,\n",
            " 'optim': 'adamw_8bit',\n",
            " 'output_dir': 'outputs',\n",
            " 'output_prompt': ' Generate atomic structure description with lattice '\n",
            "                  'lengths, angles, coordinates and atom types.',\n",
            " 'per_device_train_batch_size': 2,\n",
            " 'prefix': 'atomgpt_run',\n",
            " 'prop': 'Tc_supercon',\n",
            " 'seed_val': 42}\n",
            "   GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\n",
            "   Pytorch: 2.2.2+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "  Bfloat16 = FALSE. Xformers = 0.0.25.post1. FA = False.\n",
            "\n",
            "Testing\n",
            " 2\n",
            "  0% 0/2 [00:00<?, ?it/s]response <s>### Instruction:\n",
            "Below is a description of a superconductor material.\n",
            "### Input:\n",
            "The chemical formula is UI3 . The  Tc_supercon is 98.21. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\n",
            "### Output:\n",
            "4.78 4.78 6.11\n",
            "90 90 120\n",
            "U 0.000 0.000 0.000\n",
            "I 0.333 0.667 0.667\n",
            "I 0.667 0.333 0.333\n",
            "I 0.000 0.000 0.333</s>\n",
            "target_mat System\n",
            "1.0\n",
            "4.18 0.0 0.0\n",
            "-2.04799 7.14217 0.0\n",
            "0.0 0.0 9.96\n",
            "U I \n",
            "2 6 \n",
            "direct\n",
            "0.738 0.476 0.25 U\n",
            "0.262 0.524 0.75 U\n",
            "0.354 0.709 0.434 I\n",
            "0.646 0.291 0.566 I\n",
            "0.923 0.847 0.75 I\n",
            "0.077 0.153 0.25 I\n",
            "0.354 0.709 0.066 I\n",
            "0.646 0.291 0.934 I\n",
            "\n",
            "genmat System\n",
            "1.0\n",
            "4.78 0.0 0.0\n",
            "-2.39 4.1396 0.0\n",
            "0.0 0.0 6.11\n",
            "U I \n",
            "1 3 \n",
            "direct\n",
            "0.0 0.0 0.0 U\n",
            "0.333 0.667 0.667 I\n",
            "0.667 0.333 0.333 I\n",
            "0.0 0.0 0.333 I\n",
            "\n",
            " 50% 1/2 [00:08<00:08,  8.52s/it]response <s>### Instruction:\n",
            "Below is a description of a superconductor material.\n",
            "### Input:\n",
            "The chemical formula is TiNCl . The  Tc_supercon is 39.4. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\n",
            "### Output:\n",
            "3.08 3.11 6.88\n",
            "90 101 90\n",
            "Ti 0.499 0.000 0.133\n",
            "Ti 0.501 0.000 0.867\n",
            "N 0.999 0.000 0.500\n",
            "N 0.001 0.000 0.000\n",
            "Cl 0.499 0.000 0.657\n",
            "Cl 0.501 0.000 0.343</s>\n",
            "target_mat System\n",
            "1.0\n",
            "3.27 0.0 0.0\n",
            "0.0 3.95 0.0\n",
            "0.0 0.0 7.81\n",
            "Ti N Cl \n",
            "2 2 2 \n",
            "direct\n",
            "0.5 0.0 0.099 Ti\n",
            "0.0 0.5 0.901 Ti\n",
            "0.0 0.0 0.951 N\n",
            "0.5 0.5 0.049 N\n",
            "0.5 0.5 0.666 Cl\n",
            "0.0 0.0 0.334 Cl\n",
            "\n",
            "genmat System\n",
            "1.0\n",
            "3.02341 0.0 -0.58769\n",
            "0.0 3.11 0.0\n",
            "0.0 0.0 6.88\n",
            "Ti N Cl \n",
            "2 2 2 \n",
            "direct\n",
            "0.499 0.0 0.133 Ti\n",
            "0.501 0.0 0.867 Ti\n",
            "0.999 0.0 0.5 N\n",
            "0.001 0.0 0.0 N\n",
            "0.499 0.0 0.657 Cl\n",
            "0.501 0.0 0.343 Cl\n",
            "\n",
            "100% 2/2 [00:16<00:00,  8.48s/it]\n",
            "Time taken: 149.5400071144104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zqgAPEOSKsf5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RyKaHFL0Ksdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l39PFc7MKsbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yLZEzWHhKsZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training forward/inverse models with AtomGPT requires:\n",
        "\n",
        "# 1) `config.json` file, 2) `id_prop.csv` file."
      ],
      "metadata": {
        "id": "syLLDPebB04Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Example inverse model training for 5 materials"
      ],
      "metadata": {
        "id": "HhAC-Tfetscz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inverse Model Example"
      ],
      "metadata": {
        "id": "DVt6XyJjiUVv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to use default config:\n",
        "\n",
        "TrainingPropConfig(id_prop_path='id_prop.csv', prefix='atomgpt_run', model_name='unsloth/mistral-7b-bnb-4bit', batch_size=2, num_epochs=2, seed_val=42, num_train=2, num_val=2, num_test=2, model_save_path='lora_model_m')\n"
      ],
      "metadata": {
        "id": "t7t4PWmRA6zK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to use a small id_prop.csv dataset with 5 materials only for training as given [here](https://github.com/usnistgov/atomgpt/blob/main/atomgpt/examples/inverse_model/id_prop.csv) . For production results, use larger dataset.\n",
        "\n",
        "\n",
        "\n",
        "An example for creating a sample id_prop.csv for `\"optb88vdw_bandgap\"` bandgap is kept [here](https://github.com/usnistgov/alignn/blob/main/alignn/examples/sample_data/scripts/generate_sample_data_reg.py). For superconductor database use `\"Tc_supercon\"` key instead."
      ],
      "metadata": {
        "id": "b8hLHzxCBJ_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets' look at an example config file before running the training\n",
        "import os\n",
        "os.chdir('/content')\n",
        "from jarvis.db.jsonutils import loadjson,dumpjson\n",
        "import pprint\n",
        "config = loadjson('Software/atomgpt/atomgpt/examples/inverse_model/config.json')\n",
        "# config['model_name'] = \"knc6/atomgpt_mistral_tc_supercon\"\n",
        "dumpjson(data=config,filename='Software/atomgpt/atomgpt/examples/inverse_model/config.json')\n",
        "pprint.pprint(config)"
      ],
      "metadata": {
        "id": "ZrHsPD2VoxtO",
        "outputId": "309f7d29-7ae4-4238-d5c8-751835436b3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'alpaca_prompt': '### Instruction:\\n{}\\n### Input:\\n{}\\n### Output:\\n{}',\n",
            " 'batch_size': 2,\n",
            " 'chem_info': 'formula',\n",
            " 'csv_out': 'AI-AtomGen-prop-dft_3d-test-rmse.csv',\n",
            " 'dataset_num_proc': 2,\n",
            " 'dtype': None,\n",
            " 'gradient_accumulation_steps': 4,\n",
            " 'id_prop_path': 'atomgpt/examples/inverse_model/id_prop.csv',\n",
            " 'instruction': 'Below is a description of a superconductor material.',\n",
            " 'learning_rate': 0.0002,\n",
            " 'load_in_4bit': True,\n",
            " 'logging_steps': 1,\n",
            " 'loss_type': 'default',\n",
            " 'lr_scheduler_type': 'linear',\n",
            " 'max_seq_length': 2048,\n",
            " 'model_name': 'knc6/atomgpt_mistral_tc_supercon',\n",
            " 'model_save_path': 'lora_model_m',\n",
            " 'num_epochs': 2,\n",
            " 'num_test': 2,\n",
            " 'num_train': 2,\n",
            " 'num_val': 0,\n",
            " 'optim': 'adamw_8bit',\n",
            " 'output_dir': 'outputs',\n",
            " 'output_prompt': ' Generate atomic structure description with lattice '\n",
            "                  'lengths, angles, coordinates and atom types.',\n",
            " 'per_device_train_batch_size': 2,\n",
            " 'prefix': 'atomgpt_run',\n",
            " 'seed_val': 3407}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/Software/atomgpt')\n",
        "!atomgpt_inverse_train --config_name atomgpt/examples/inverse_model/config.json\n",
        "#!python Software/atomgpt/atomgpt/inverse_models/inverse_models.py --config_name Software/atomgpt/atomgpt/examples/inverse_model/config.json"
      ],
      "metadata": {
        "id": "dPgJz-gxG5e5",
        "outputId": "521b30d9-9fa1-4fb6-9a3f-d3c94daa3074",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_save_path\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "\n",
            "         _                   _____ _____ _______ \n",
            "    /\\  | |                 / ____|  __ \\__   __|\n",
            "   /  \\ | |_ ___  _ __ ___ | |  __| |__) | | |   \n",
            "  / /\\ \\| __/ _ \\| '_ ` _ \\| | |_ |  ___/  | |   \n",
            " / ____ \\ || (_) | | | | | | |__| | |      | |   \n",
            "/_/    \\_\\__\\___/|_| |_| |_|\\_____|_|      |_|   \n",
            "   \n",
            "config_file atomgpt/examples/inverse_model/config.json\n",
            "{'alpaca_prompt': '### Instruction:\\n{}\\n### Input:\\n{}\\n### Output:\\n{}',\n",
            " 'batch_size': 2,\n",
            " 'chem_info': 'formula',\n",
            " 'csv_out': 'AI-AtomGen-prop-dft_3d-test-rmse.csv',\n",
            " 'dataset_num_proc': 2,\n",
            " 'dtype': None,\n",
            " 'file_format': 'poscar',\n",
            " 'gradient_accumulation_steps': 4,\n",
            " 'id_prop_path': 'atomgpt/examples/inverse_model/id_prop.csv',\n",
            " 'id_tag': 'id',\n",
            " 'instruction': 'Below is a description of a superconductor material.',\n",
            " 'learning_rate': 0.0002,\n",
            " 'load_in_4bit': True,\n",
            " 'logging_steps': 1,\n",
            " 'loss_type': 'default',\n",
            " 'lr_scheduler_type': 'linear',\n",
            " 'max_seq_length': 2048,\n",
            " 'model_name': 'knc6/atomgpt_mistral_tc_supercon',\n",
            " 'model_save_path': 'lora_model_m',\n",
            " 'num_epochs': 2,\n",
            " 'num_test': 2,\n",
            " 'num_train': 2,\n",
            " 'num_val': 0,\n",
            " 'optim': 'adamw_8bit',\n",
            " 'output_dir': 'outputs',\n",
            " 'output_prompt': ' Generate atomic structure description with lattice '\n",
            "                  'lengths, angles, coordinates and atom types.',\n",
            " 'per_device_train_batch_size': 2,\n",
            " 'prefix': 'atomgpt_run',\n",
            " 'prop': 'Tc_supercon',\n",
            " 'seed_val': 3407}\n",
            "\r  0% 0/6 [00:00<?, ?it/s]\r100% 6/6 [00:00<00:00, 301.74it/s]\n",
            "outputs/alpaca_prop_train.json  exists\n",
            "Sample:\n",
            " {'instruction': 'Below is a description of a superconductor material.', 'input': 'The chemical formula is NaZnP . The  Tc_supercon is 124.8. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.', 'output': '4.07 4.07 6.89\\n90 90 90\\nNa 0.000 0.500 0.644\\nNa 0.500 0.000 0.356\\nZn 0.000 0.000 0.000\\nZn 0.500 0.500 0.000\\nP 0.500 0.000 0.785\\nP 0.000 0.500 0.215'}\n",
            "outputs/alpaca_prop_test.json exists\n",
            "   GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\n",
            "   Pytorch: 2.2.2+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "  Bfloat16 = FALSE. Xformers = 0.0.25.post1. FA = False.\n",
            "\n",
            "Unsloth 2024.5 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n",
            "Map (num_proc=2): 100% 2/2 [00:00<00:00,  5.07 examples/s]\n",
            "/usr/local/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
            "  warnings.warn(\n",
            "Num GPUs = 1\n",
            "Num examples = 2 | Num Epochs = 2\n",
            "Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "Total batch size = 8 | Total steps = 2\n",
            "Number of trainable parameters = 41,943,040\n",
            "{'loss': 0.3134, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 1.0}\n",
            "{'loss': 0.3134, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 2.0}\n",
            "{'train_runtime': 6.4812, 'train_samples_per_second': 0.617, 'train_steps_per_second': 0.309, 'train_loss': 0.31335602700710297, 'epoch': 2.0}\n",
            "100% 2/2 [00:06<00:00,  3.24s/it]\n",
            "   GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\n",
            "   Pytorch: 2.2.2+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "  Bfloat16 = FALSE. Xformers = 0.0.25.post1. FA = False.\n",
            "\n",
            "{'alpaca_prompt': '### Instruction:\\n{}\\n### Input:\\n{}\\n### Output:\\n{}',\n",
            " 'batch_size': 2,\n",
            " 'chem_info': 'formula',\n",
            " 'csv_out': 'AI-AtomGen-prop-dft_3d-test-rmse.csv',\n",
            " 'dataset_num_proc': 2,\n",
            " 'dtype': None,\n",
            " 'file_format': 'poscar',\n",
            " 'gradient_accumulation_steps': 4,\n",
            " 'id_prop_path': 'atomgpt/examples/inverse_model/id_prop.csv',\n",
            " 'id_tag': 'id',\n",
            " 'instruction': 'Below is a description of a superconductor material.',\n",
            " 'learning_rate': 0.0002,\n",
            " 'load_in_4bit': True,\n",
            " 'logging_steps': 1,\n",
            " 'loss_type': 'default',\n",
            " 'lr_scheduler_type': 'linear',\n",
            " 'max_seq_length': 2048,\n",
            " 'model_name': 'knc6/atomgpt_mistral_tc_supercon',\n",
            " 'model_save_path': 'lora_model_m',\n",
            " 'num_epochs': 2,\n",
            " 'num_test': 2,\n",
            " 'num_train': 2,\n",
            " 'num_val': 0,\n",
            " 'optim': 'adamw_8bit',\n",
            " 'output_dir': 'outputs',\n",
            " 'output_prompt': ' Generate atomic structure description with lattice '\n",
            "                  'lengths, angles, coordinates and atom types.',\n",
            " 'per_device_train_batch_size': 2,\n",
            " 'prefix': 'atomgpt_run',\n",
            " 'prop': 'Tc_supercon',\n",
            " 'seed_val': 3407}\n",
            "   GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\n",
            "   Pytorch: 2.2.2+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "  Bfloat16 = FALSE. Xformers = 0.0.25.post1. FA = False.\n",
            "\n",
            "Testing\n",
            " 2\n",
            "  0% 0/2 [00:00<?, ?it/s]response <s>### Instruction:\n",
            "Below is a description of a superconductor material.\n",
            "### Input:\n",
            "The chemical formula is UI3 . The  Tc_supercon is 98.21. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\n",
            "### Output:\n",
            "4.78 4.78 6.11\n",
            "90 90 120\n",
            "U 0.000 0.000 0.000\n",
            "I 0.333 0.667 0.667\n",
            "I 0.667 0.333 0.333\n",
            "I 0.000 0.000 0.333</s>\n",
            "target_mat System\n",
            "1.0\n",
            "4.18 0.0 0.0\n",
            "-2.04799 7.14217 0.0\n",
            "0.0 0.0 9.96\n",
            "U I \n",
            "2 6 \n",
            "direct\n",
            "0.738 0.476 0.25 U\n",
            "0.262 0.524 0.75 U\n",
            "0.354 0.709 0.434 I\n",
            "0.646 0.291 0.566 I\n",
            "0.923 0.847 0.75 I\n",
            "0.077 0.153 0.25 I\n",
            "0.354 0.709 0.066 I\n",
            "0.646 0.291 0.934 I\n",
            "\n",
            "genmat System\n",
            "1.0\n",
            "4.78 0.0 0.0\n",
            "-2.39 4.1396 0.0\n",
            "0.0 0.0 6.11\n",
            "U I \n",
            "1 3 \n",
            "direct\n",
            "0.0 0.0 0.0 U\n",
            "0.333 0.667 0.667 I\n",
            "0.667 0.333 0.333 I\n",
            "0.0 0.0 0.333 I\n",
            "\n",
            " 50% 1/2 [00:07<00:07,  7.45s/it]response <s>### Instruction:\n",
            "Below is a description of a superconductor material.\n",
            "### Input:\n",
            "The chemical formula is TiNCl . The  Tc_supercon is 39.4. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\n",
            "### Output:\n",
            "3.08 3.11 6.88\n",
            "90 101 90\n",
            "Ti 0.499 0.000 0.133\n",
            "Ti 0.501 0.000 0.867\n",
            "N 0.999 0.000 0.500\n",
            "N 0.001 0.000 0.000\n",
            "Cl 0.499 0.000 0.657\n",
            "Cl 0.501 0.000 0.343</s>\n",
            "target_mat System\n",
            "1.0\n",
            "3.27 0.0 0.0\n",
            "0.0 3.95 0.0\n",
            "0.0 0.0 7.81\n",
            "Ti N Cl \n",
            "2 2 2 \n",
            "direct\n",
            "0.5 0.0 0.099 Ti\n",
            "0.0 0.5 0.901 Ti\n",
            "0.0 0.0 0.951 N\n",
            "0.5 0.5 0.049 N\n",
            "0.5 0.5 0.666 Cl\n",
            "0.0 0.0 0.334 Cl\n",
            "\n",
            "genmat System\n",
            "1.0\n",
            "3.02341 0.0 -0.58769\n",
            "0.0 3.11 0.0\n",
            "0.0 0.0 6.88\n",
            "Ti N Cl \n",
            "2 2 2 \n",
            "direct\n",
            "0.499 0.0 0.133 Ti\n",
            "0.501 0.0 0.867 Ti\n",
            "0.999 0.0 0.5 N\n",
            "0.001 0.0 0.0 N\n",
            "0.499 0.0 0.657 Cl\n",
            "0.501 0.0 0.343 Cl\n",
            "\n",
            "100% 2/2 [00:16<00:00,  8.31s/it]\n",
            "Time taken: 75.54917502403259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from atomgpt.inverse_models.inverse_models import gen_atoms\n",
        "# from atomgpt.inverse_models import  FastLanguageModel\n",
        "\n",
        "# alpaca_prompt = \"\"\"Below is a description of a superconductor material..\n",
        "\n",
        "# ### Instruction:\n",
        "# {}\n",
        "\n",
        "# ### Input:\n",
        "# {}\n",
        "\n",
        "# ### Output:\n",
        "# {}\"\"\"\n",
        "\n",
        "# max_seq_length = 2048  # Choose any! We auto support RoPE Scaling internally!\n",
        "# dtype = None  #\n",
        "# load_in_4bit = True\n",
        "# model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "#     model_name = \"lora_model_m\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "#     max_seq_length = max_seq_length,\n",
        "#     dtype = dtype,\n",
        "#     load_in_4bit = load_in_4bit,\n",
        "#     device_map=\"auto\"\n",
        "\n",
        "# )\n",
        "# FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "\n",
        "# # Example prompt and generated structure\n",
        "# if __name__==\"__main__\":\n",
        "#  prompt_example = \"The chemical formula is FeBN The  prop is 36.483. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\"\n",
        "\n",
        "#  gen_mat = gen_atoms(prompt=prompt_example,model=model,tokenizer=tokenizer)\n",
        "#  print(gen_mat)"
      ],
      "metadata": {
        "id": "5FDQhK6MX5Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python atomgpt/inverse_models/inverse_predict.py --output_dir outputs/ --pred_csv \"atomgpt/examples/inverse_model/pred_list_inverse.csv\""
      ],
      "metadata": {
        "id": "DW_eXcZfX5Mq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea885f2b-032a-42b0-9623-99b4cc602bb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_save_path\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "{'alpaca_prompt': '### Instruction:\\n{}\\n### Input:\\n{}\\n### Output:\\n{}',\n",
            " 'batch_size': 2,\n",
            " 'chem_info': 'formula',\n",
            " 'csv_out': 'AI-AtomGen-prop-dft_3d-test-rmse.csv',\n",
            " 'dataset_num_proc': 2,\n",
            " 'dtype': None,\n",
            " 'file_format': 'poscar',\n",
            " 'gradient_accumulation_steps': 4,\n",
            " 'id_prop_path': 'atomgpt/examples/inverse_model/id_prop.csv',\n",
            " 'id_tag': 'id',\n",
            " 'instruction': 'Below is a description of a superconductor material.',\n",
            " 'learning_rate': 0.0002,\n",
            " 'load_in_4bit': True,\n",
            " 'logging_steps': 1,\n",
            " 'loss_type': 'default',\n",
            " 'lr_scheduler_type': 'linear',\n",
            " 'max_seq_length': 2048,\n",
            " 'model_name': 'knc6/atomgpt_mistral_tc_supercon',\n",
            " 'model_save_path': 'lora_model_m',\n",
            " 'num_epochs': 2,\n",
            " 'num_test': 2,\n",
            " 'num_train': 2,\n",
            " 'num_val': 0,\n",
            " 'optim': 'adamw_8bit',\n",
            " 'output_dir': 'outputs',\n",
            " 'output_prompt': ' Generate atomic structure description with lattice '\n",
            "                  'lengths, angles, coordinates and atom types.',\n",
            " 'per_device_train_batch_size': 2,\n",
            " 'prefix': 'atomgpt_run',\n",
            " 'prop': 'Tc_supercon',\n",
            " 'seed_val': 3407}\n",
            "   GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\n",
            "   Pytorch: 2.2.2+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "  Bfloat16 = FALSE. Xformers = 0.0.25.post1. FA = False.\n",
            "\n",
            "Unsloth 2024.5 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n",
            "prompt The chemical formula is FeBN. The  prop is 36.483. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\n",
            "response <s>### Instruction:\n",
            "Below is a description of a superconductor material.\n",
            "### Input:\n",
            "The chemical formula is FeBN. The  prop is 36.483. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\n",
            "### Output:\n",
            "3.02 3.05 5.11\n",
            "90 108 90\n",
            "Fe 0.853 0.000 0.292\n",
            "Fe 0.147 0.000 0.708\n",
            "B 0.579 0.000 0.005\n",
            "B 0.421 0.000 0.995\n",
            "N 0.256 0.571 0.628\n",
            "N 0.744 0.429 0.372</s>\n",
            "gen atoms System\n",
            "1.0\n",
            "2.87219 0.0 -0.93323\n",
            "0.0 3.05 0.0\n",
            "0.0 0.0 5.11\n",
            "Fe B N \n",
            "2 2 2 \n",
            "direct\n",
            "0.853 0.0 0.292 Fe\n",
            "0.147 0.0 0.708 Fe\n",
            "0.579 0.0 0.005 B\n",
            "0.421 0.0 0.995 B\n",
            "0.256 0.571 0.628 N\n",
            "0.744 0.429 0.372 N\n",
            "\n",
            "prompt The chemical formula is MgC2. The  prop is 36.483. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\n",
            "response <s>### Instruction:\n",
            "Below is a description of a superconductor material.\n",
            "### Input:\n",
            "The chemical formula is MgC2. The  prop is 36.483. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\n",
            "### Output:\n",
            "3.14 3.15 5.21\n",
            "90 109 90\n",
            "Mg 0.000 0.000 0.000\n",
            "C 0.333 0.500 0.238\n",
            "C 0.667 0.500 0.762</s>\n",
            "gen atoms System\n",
            "1.0\n",
            "2.96893 0.0 -1.02228\n",
            "0.0 3.15 0.0\n",
            "0.0 0.0 5.21\n",
            "Mg C \n",
            "1 2 \n",
            "direct\n",
            "0.0 0.0 0.0 Mg\n",
            "0.333 0.5 0.238 C\n",
            "0.667 0.5 0.762 C\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-IdyEJXzX5Ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XPO4Cf4EX5H7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extras"
      ],
      "metadata": {
        "id": "Q_R0bYP6ZBFL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S0rNEtR0X5Fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "id": "yzZyPb33AEll",
        "outputId": "9a4363e1-ee75-4a3b-f5de-9e60f730dfdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI-AtomGen-prop-dft_3d-test-rmse.csv  huggingface_tokenizers_cache  outputs\n",
            "atomgpt\t\t\t\t      LICENSE.rst\t\t    pyproject.toml1\n",
            "atomgpt.egg-info\t\t      lora_model_m\t\t    README.md\n",
            "atomgpt_inverse_config.json\t      Out\t\t\t    requirements.txt\n",
            "environment.yml\t\t\t      out_inv.json\t\t    setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Files such as `AI-AtomGen-prop-dft_3d-test-rmse.csv ` can be uploaded in the [JARVIS-Leaderboard](https://pages.nist.gov/jarvis_leaderboard/) benchmarking plotform.\n",
        "\n"
      ],
      "metadata": {
        "id": "UUkS9YNgrBM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The models are saved in the folder `lora_model_m`"
      ],
      "metadata": {
        "id": "nvURZAxFrtVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls lora_model_m"
      ],
      "metadata": {
        "id": "Or-1ZO_arNHo",
        "outputId": "55ba77b8-6ea2-4e62-802c-ac69e081c34b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adapter_config.json  adapter_model.safetensors\tconfig.json  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at `alpaca_prop_test.json` and `alpaca_prop_train.json`"
      ],
      "metadata": {
        "id": "f1UdRnNorUN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls outputs/"
      ],
      "metadata": {
        "id": "QGleMuinzrVT",
        "outputId": "263142fc-6a8a-438a-9f00-191a868f4174",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpaca_prop_test.json  alpaca_prop_train.json  config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpaca_prop_test=loadjson('outputs/alpaca_prop_test.json')\n",
        "alpaca_prop_train=loadjson('outputs/alpaca_prop_train.json')\n",
        "print(len(alpaca_prop_test),len(alpaca_prop_train))\n",
        "print('\\n')\n",
        "pprint.pprint(alpaca_prop_train[0])\n",
        "print('\\n')\n"
      ],
      "metadata": {
        "id": "ymYpnxvErTzW",
        "outputId": "da8f02c6-57df-4619-e688-e680f218f3ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 2\n",
            "\n",
            "\n",
            "{'input': 'The chemical formula is NaZnP . The  Tc_supercon is 124.8. Generate '\n",
            "          'atomic structure description with lattice lengths, angles, '\n",
            "          'coordinates and atom types.',\n",
            " 'instruction': 'Below is a description of a superconductor material.',\n",
            " 'output': '4.07 4.07 6.89\\n'\n",
            "           '90 90 90\\n'\n",
            "           'Na 0.000 0.500 0.644\\n'\n",
            "           'Na 0.500 0.000 0.356\\n'\n",
            "           'Zn 0.000 0.000 0.000\\n'\n",
            "           'Zn 0.500 0.500 0.000\\n'\n",
            "           'P 0.500 0.000 0.785\\n'\n",
            "           'P 0.000 0.500 0.215'}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Using the trained model for inference"
      ],
      "metadata": {
        "id": "IBz34xi_tztU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's load the trained model for inference/testing. Note again this model was trained on just a few samples, so accuracy wont be very high."
      ],
      "metadata": {
        "id": "-lt2RgZmr0ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from jarvis.db.jsonutils import loadjson\n",
        "# from atomgpt.inverse_models import  FastLanguageModel\n",
        "# import torch\n",
        "# from datasets import load_dataset\n",
        "# from trl import SFTTrainer\n",
        "# from transformers import TrainingArguments\n",
        "# from jarvis.core.atoms import Atoms\n",
        "# from jarvis.db.figshare import data\n",
        "# from jarvis.db.jsonutils import loadjson, dumpjson\n",
        "# import numpy as np\n",
        "# from jarvis.core.atoms import Atoms\n",
        "# from jarvis.core.lattice import Lattice\n",
        "# from tqdm import tqdm\n",
        "# from jarvis.io.vasp.inputs import Poscar\n",
        "\n",
        "# import os\n",
        "# #os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
        "# #torch.cuda.is_available = lambda : False\n",
        "# alpaca_prompt = \"\"\"Below is a description of a superconductor material..\n",
        "\n",
        "# ### Instruction:\n",
        "# {}\n",
        "\n",
        "# ### Input:\n",
        "# {}\n",
        "\n",
        "# ### Output:\n",
        "# {}\"\"\"\n",
        "\n",
        "# max_seq_length = 2048  # Choose any! We auto support RoPE Scaling internally!\n",
        "# dtype = None  #\n",
        "# load_in_4bit = True\n",
        "# model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "#     model_name = \"lora_model_m\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "#     max_seq_length = max_seq_length,\n",
        "#     dtype = dtype,\n",
        "#     load_in_4bit = load_in_4bit,\n",
        "#     device_map=\"auto\"\n",
        "\n",
        "# )\n",
        "# FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "\n",
        "# def text2atoms(response):\n",
        "#     tmp_atoms_array = response.split(\"\\n\")\n",
        "#     lat_lengths = np.array(tmp_atoms_array[1].split(), dtype=\"float\")\n",
        "#     lat_angles = np.array(tmp_atoms_array[2].split(), dtype=\"float\")\n",
        "#     lat = Lattice.from_parameters(\n",
        "#         lat_lengths[0],\n",
        "#         lat_lengths[1],\n",
        "#         lat_lengths[2],\n",
        "#         lat_angles[0],\n",
        "#         lat_angles[1],\n",
        "#         lat_angles[2],\n",
        "#     )\n",
        "#     elements = []\n",
        "#     coords = []\n",
        "#     for ii, i in enumerate(tmp_atoms_array):\n",
        "#         if ii > 2 and ii < len(tmp_atoms_array):\n",
        "#             tmp = i.split()\n",
        "#             elements.append(tmp[0])\n",
        "#             coords.append([float(tmp[1]), float(tmp[2]), float(tmp[3])])\n",
        "#     atoms = Atoms(\n",
        "#         coords=coords,\n",
        "#         elements=elements,\n",
        "#         lattice_mat=lat.lattice(),\n",
        "#         cartesian=False,\n",
        "#     )\n",
        "#     return atoms\n",
        "\n",
        "# def gen_atoms(prompt=\"\", max_new_tokens=512, model=\"\", tokenizer=\"\"):\n",
        "#     inputs = tokenizer(\n",
        "#         [\n",
        "#             alpaca_prompt.format(\n",
        "#                 \"Below is a description of a superconductor material.\",  # instruction\n",
        "#                 prompt,  # input\n",
        "#                 \"\",  # output - leave this blank for generation!\n",
        "#             )\n",
        "#         ],\n",
        "#         return_tensors=\"pt\",\n",
        "#     ).to(\"cuda\")\n",
        "#     outputs = model.generate(\n",
        "#         **inputs, max_new_tokens=max_new_tokens, use_cache=True\n",
        "#     )\n",
        "#     response = tokenizer.batch_decode(outputs)[0].split(\"# Output:\")[1].strip('</s>')\n",
        "#     # print('response',response)\n",
        "#     atoms = text2atoms(response)\n",
        "#     return atoms\n",
        "\n",
        "# if __name__==\"__main__\":\n",
        "#  prompt_example = \"The chemical formula is MgB2 The  Tc_supercon is 6.483. The spacegroup is 12. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\"\n",
        "#  prompt_example = \"The chemical formula is FeBN The  Tc_supercon is 36.483. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\"\n",
        "\n",
        "#  gen_mat = gen_atoms(prompt=prompt_example,model=model,tokenizer=tokenizer)\n",
        "#  print(gen_mat)"
      ],
      "metadata": {
        "id": "Z0Gf0CKSr8oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Relaxing structures with ALIGNN-FF"
      ],
      "metadata": {
        "id": "SOp5oZSpt68_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The generated atomic structures can be relaxed with ALIGNN-FF, see example [here](https://colab.research.google.com/github/knc6/jarvis-tools-notebooks/blob/master/jarvis-tools-notebooks/ALIGNN_Structure_Relaxation_Phonons_Interface.ipynb)."
      ],
      "metadata": {
        "id": "wLEaeWSkstav"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above example used 5 materials during train only. We used about 1000 materials database in JARVIS-DFT, and the fine-tuned model is kept on [huggingface](https://huggingface.co/knc6/atomgpt_mistral_tc_supercon)."
      ],
      "metadata": {
        "id": "BkzSijjds4o5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Generating a database"
      ],
      "metadata": {
        "id": "IDpOtWsLuABd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from jarvis.core.specie import atomic_numbers_to_symbols\n",
        "# import numpy as np\n",
        "# from jarvis.db.jsonutils import loadjson, dumpjson\n",
        "# from jarvis.core.composition import Composition\n",
        "# from tqdm import tqdm\n",
        "# from inf import gen_atoms\n",
        "\n",
        "# Z = np.arange(100) + 1\n",
        "# els = atomic_numbers_to_symbols(Z)\n",
        "\n",
        "# m = 1\n",
        "# n = 2\n",
        "\n",
        "\n",
        "# def gen_binary_samples(element=\"B\"):\n",
        "#     mem = []\n",
        "#     for m in np.arange(1, 4):\n",
        "#         for n in np.arange(1, 4):\n",
        "#             for i in tqdm(els):\n",
        "#                 try:\n",
        "#                     comp = Composition.from_dict({i: m, element: n})\n",
        "#                     prompt_example = (\n",
        "#                         \"The chemical formula is \"\n",
        "#                         + comp.reduced_formula\n",
        "#                         + \" The  Tc_supercon is 100. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\"\n",
        "#                     )\n",
        "#                     gen_mat = gen_atoms(prompt_example)\n",
        "#                     print(i)\n",
        "#                     print(gen_mat, len(mem))\n",
        "#                     mem.append([int(m), int(n), i, gen_mat.to_dict()])\n",
        "#                     # dumpjson(data=mem,filename='superB.json')\n",
        "#                 except:\n",
        "#                     pass\n",
        "#     fname=\"binary_super\"+element+\".json\"\n",
        "#     dumpjson(data=mem, filename=fname)\n",
        "# gen_binary_samples(\"S\")\n",
        "# gen_binary_samples(\"Se\")\n",
        "# gen_binary_samples(\"Te\")\n",
        "# def gen_ternary_samples(element=\"B\"):\n",
        "#     mem = []\n",
        "#     for m in np.arange(1, 4):\n",
        "#         for n in np.arange(1, 4):\n",
        "#           for j in tqdm(els):\n",
        "#             for i in tqdm(els):\n",
        "#                 try:\n",
        "#                     comp = Composition.from_dict({i: m, j:n, element: n})\n",
        "#                     prompt_example = (\n",
        "#                         \"The chemical formula is \"\n",
        "#                         + comp.reduced_formula\n",
        "#                         + \" The  Tc_supercon is 100. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\"\n",
        "#                     )\n",
        "#                     gen_mat = gen_atoms(prompt_example)\n",
        "#                     print(i)\n",
        "#                     print(gen_mat, len(mem))\n",
        "#                     mem.append([int(m), int(n), i, gen_mat.to_dict()])\n",
        "#                     # dumpjson(data=mem,filename='superB.json')\n",
        "#                 except:\n",
        "#                     pass\n",
        "#     fname=\"binary_super\"+element+\".json\"\n",
        "#     dumpjson(data=mem, filename=fname)\n",
        "# gen_ternary_samples(\"B\")\n",
        "\n",
        "# \"\"\"\n",
        "\n",
        "# m=1\n",
        "# n=2\n",
        "# mem=[]\n",
        "# for m in np.arange(1,4):\n",
        "#   for n in np.arange(1,4):\n",
        "#     for i in tqdm(els):\n",
        "#       try:\n",
        "#         comp=Composition.from_dict({i:m,\"C\":n})\n",
        "#         prompt_example = \"The chemical formula is \"+comp.reduced_formula+\" The  Tc_supercon is 100. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\"\n",
        "#         gen_mat = gen_atoms(prompt_example)\n",
        "#         print(i)\n",
        "#         print(gen_mat,len(mem))\n",
        "#         mem.append([int(m),int(n),i,gen_mat.to_dict()])\n",
        "#         #mem.append([m,n,i,gen_mat.to_dict()])\n",
        "#       except:\n",
        "#         pass\n",
        "# dumpjson(data=mem,filename='superC.json')\n",
        "\n",
        "\n",
        "\n",
        "# m=1\n",
        "# n=2\n",
        "# mem=[]\n",
        "# for m in np.arange(1,4):\n",
        "#   for n in np.arange(1,4):\n",
        "#     for i in tqdm(els):\n",
        "#       try:\n",
        "#         comp=Composition.from_dict({i:m,\"N\":n})\n",
        "#         prompt_example = \"The chemical formula is \"+comp.reduced_formula+\" The  Tc_supercon is 100. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\"\n",
        "#         gen_mat = gen_atoms(prompt_example)\n",
        "#         print(i)\n",
        "#         print(gen_mat,len(mem))\n",
        "#         mem.append([int(m),int(n),i,gen_mat.to_dict()])\n",
        "#         #mem.append([m,n,i,gen_mat.to_dict()])\n",
        "#       except:\n",
        "#         pass\n",
        "# dumpjson(data=mem,filename='superN.json')\n",
        "# \"\"\"\n"
      ],
      "metadata": {
        "id": "k5qoILFysR-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For forward model training with AtomGPT, see https://colab.research.google.com/github/knc6/jarvis-tools-notebooks/blob/master/jarvis-tools-notebooks/atomgpt_forward_example.ipynb"
      ],
      "metadata": {
        "id": "3S-GrT1LEAMv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K_6ZFPJMsR7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g4Px2rjJz_AL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q4ulYeQizxii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Ae04L4JgC05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!conda env export"
      ],
      "metadata": {
        "id": "-IUbsYWmgCx_",
        "outputId": "66ba204b-dc5a-47f4-8221-6fe4949328cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name: base\n",
            "channels:\n",
            "  - conda-forge\n",
            "dependencies:\n",
            "  - _libgcc_mutex=0.1=conda_forge\n",
            "  - _openmp_mutex=4.5=2_gnu\n",
            "  - archspec=0.2.2=pyhd8ed1ab_0\n",
            "  - boltons=23.1.1=pyhd8ed1ab_0\n",
            "  - brotli-python=1.1.0=py310hc6cd4ac_1\n",
            "  - bzip2=1.0.8=hd590300_5\n",
            "  - c-ares=1.24.0=hd590300_0\n",
            "  - ca-certificates=2023.11.17=hbcca054_0\n",
            "  - cffi=1.16.0=py310h2fee648_0\n",
            "  - charset-normalizer=3.3.2=pyhd8ed1ab_0\n",
            "  - colorama=0.4.6=pyhd8ed1ab_0\n",
            "  - conda=23.11.0=py310hff52083_1\n",
            "  - conda-libmamba-solver=23.12.0=pyhd8ed1ab_0\n",
            "  - conda-package-handling=2.2.0=pyh38be061_0\n",
            "  - conda-package-streaming=0.9.0=pyhd8ed1ab_0\n",
            "  - distro=1.8.0=pyhd8ed1ab_0\n",
            "  - fmt=10.1.1=h00ab1b0_1\n",
            "  - icu=73.2=h59595ed_0\n",
            "  - jsonpatch=1.33=pyhd8ed1ab_0\n",
            "  - jsonpointer=2.4=py310hff52083_3\n",
            "  - keyutils=1.6.1=h166bdaf_0\n",
            "  - krb5=1.21.2=h659d440_0\n",
            "  - ld_impl_linux-64=2.40=h41732ed_0\n",
            "  - libarchive=3.7.2=h2aa1ff5_1\n",
            "  - libcurl=8.5.0=hca28451_0\n",
            "  - libedit=3.1.20191231=he28a2e2_2\n",
            "  - libev=4.33=hd590300_2\n",
            "  - libffi=3.4.2=h7f98852_5\n",
            "  - libgcc-ng=13.2.0=h807b86a_3\n",
            "  - libgomp=13.2.0=h807b86a_3\n",
            "  - libiconv=1.17=hd590300_2\n",
            "  - libmamba=1.5.5=had39da4_0\n",
            "  - libmambapy=1.5.5=py310h39ff949_0\n",
            "  - libnghttp2=1.58.0=h47da74e_1\n",
            "  - libnsl=2.0.1=hd590300_0\n",
            "  - libsolv=0.7.27=hfc55251_0\n",
            "  - libsqlite=3.44.2=h2797004_0\n",
            "  - libssh2=1.11.0=h0841786_0\n",
            "  - libstdcxx-ng=13.2.0=h7e041cc_3\n",
            "  - libuuid=2.38.1=h0b41bf4_0\n",
            "  - libxml2=2.12.3=h232c23b_0\n",
            "  - libzlib=1.2.13=hd590300_5\n",
            "  - lz4-c=1.9.4=hcb278e6_0\n",
            "  - lzo=2.10=h516909a_1000\n",
            "  - mamba=1.5.5=py310h51d5547_0\n",
            "  - menuinst=2.0.1=py310hff52083_0\n",
            "  - ncurses=6.4=h59595ed_2\n",
            "  - openssl=3.2.0=hd590300_1\n",
            "  - pip=23.3.2=pyhd8ed1ab_0\n",
            "  - pluggy=1.3.0=pyhd8ed1ab_0\n",
            "  - pybind11-abi=4=hd8ed1ab_3\n",
            "  - pycosat=0.6.6=py310h2372a71_0\n",
            "  - pycparser=2.21=pyhd8ed1ab_0\n",
            "  - pysocks=1.7.1=pyha2e5f31_6\n",
            "  - python=3.10.13=hd12c33a_0_cpython\n",
            "  - python_abi=3.10=4_cp310\n",
            "  - readline=8.2=h8228510_1\n",
            "  - reproc=14.2.4.post0=hd590300_1\n",
            "  - reproc-cpp=14.2.4.post0=h59595ed_1\n",
            "  - ruamel.yaml=0.18.5=py310h2372a71_0\n",
            "  - ruamel.yaml.clib=0.2.7=py310h2372a71_2\n",
            "  - setuptools=68.2.2=pyhd8ed1ab_0\n",
            "  - tk=8.6.13=noxft_h4845f30_101\n",
            "  - truststore=0.8.0=pyhd8ed1ab_0\n",
            "  - wheel=0.42.0=pyhd8ed1ab_0\n",
            "  - xz=5.2.6=h166bdaf_0\n",
            "  - yaml-cpp=0.8.0=h59595ed_0\n",
            "  - zstandard=0.22.0=py310h1275a96_0\n",
            "  - zstd=1.5.5=hfc55251_0\n",
            "  - pip:\n",
            "      - accelerate==0.31.0\n",
            "      - aiohttp==3.9.5\n",
            "      - aiosignal==1.3.1\n",
            "      - alignn==2024.4.20\n",
            "      - annotated-types==0.7.0\n",
            "      - ase==3.23.0\n",
            "      - async-timeout==4.0.3\n",
            "      - attrs==23.2.0\n",
            "      - autopep8==2.3.1\n",
            "      - bitsandbytes==0.43.1\n",
            "      - black==24.4.2\n",
            "      - certifi==2024.6.2\n",
            "      - chardet==3.0.4\n",
            "      - click==8.1.7\n",
            "      - contourpy==1.2.1\n",
            "      - cycler==0.12.1\n",
            "      - datasets==2.20.0\n",
            "      - dgl==1.1.1\n",
            "      - dill==0.3.8\n",
            "      - docstring-parser==0.16\n",
            "      - eval-type-backport==0.2.0\n",
            "      - filelock==3.15.4\n",
            "      - flake8==7.1.0\n",
            "      - fonttools==4.53.0\n",
            "      - frozenlist==1.4.1\n",
            "      - fsspec==2024.5.0\n",
            "      - gmpy2==2.2.1\n",
            "      - huggingface-hub==0.23.4\n",
            "      - idna==3.7\n",
            "      - importlib-resources==6.4.0\n",
            "      - jarvis-tools==2024.4.30\n",
            "      - jinja2==3.1.4\n",
            "      - joblib==1.4.2\n",
            "      - kiwisolver==1.4.5\n",
            "      - lmdb==1.4.1\n",
            "      - markdown-it-py==3.0.0\n",
            "      - markupsafe==2.1.5\n",
            "      - matplotlib==3.9.0\n",
            "      - mccabe==0.7.0\n",
            "      - mdurl==0.1.2\n",
            "      - mpmath==1.3.0\n",
            "      - multidict==4.7.6\n",
            "      - multiprocess==0.70.16\n",
            "      - mypy-extensions==1.0.0\n",
            "      - networkx==3.3\n",
            "      - numpy==1.26.4\n",
            "      - nvidia-cublas-cu12==12.1.3.1\n",
            "      - nvidia-cuda-cupti-cu12==12.1.105\n",
            "      - nvidia-cuda-nvrtc-cu12==12.1.105\n",
            "      - nvidia-cuda-runtime-cu12==12.1.105\n",
            "      - nvidia-cudnn-cu12==8.9.2.26\n",
            "      - nvidia-cufft-cu12==11.0.2.54\n",
            "      - nvidia-curand-cu12==10.3.2.106\n",
            "      - nvidia-cusolver-cu12==11.4.5.107\n",
            "      - nvidia-cusparse-cu12==12.1.0.106\n",
            "      - nvidia-nccl-cu12==2.19.3\n",
            "      - nvidia-nvjitlink-cu12==12.6.20\n",
            "      - nvidia-nvtx-cu12==12.1.105\n",
            "      - packaging==24.1\n",
            "      - pandas==2.2.2\n",
            "      - pathspec==0.12.1\n",
            "      - peft==0.11.1\n",
            "      - pillow==10.3.0\n",
            "      - platformdirs==4.2.2\n",
            "      - protobuf==5.27.3\n",
            "      - psutil==6.0.0\n",
            "      - pyarrow==16.1.0\n",
            "      - pyarrow-hotfix==0.6\n",
            "      - pycodestyle==2.12.0\n",
            "      - pydantic==2.7.4\n",
            "      - pydantic-core==2.18.4\n",
            "      - pydantic-settings==2.3.3\n",
            "      - pydocstyle==6.3.0\n",
            "      - pyflakes==3.2.0\n",
            "      - pygments==2.18.0\n",
            "      - pyparsing==2.4.7\n",
            "      - python-dateutil==2.9.0.post0\n",
            "      - python-dotenv==1.0.1\n",
            "      - pytz==2024.1\n",
            "      - pyyaml==6.0.2\n",
            "      - regex==2024.5.15\n",
            "      - requests==2.32.3\n",
            "      - rich==13.7.1\n",
            "      - safetensors==0.4.3\n",
            "      - scikit-learn==1.5.0\n",
            "      - scipy==1.13.1\n",
            "      - sentencepiece==0.2.0\n",
            "      - shtab==1.7.1\n",
            "      - six==1.16.0\n",
            "      - snowballstemmer==2.2.0\n",
            "      - spglib==2.4.0\n",
            "      - sympy==1.13.1\n",
            "      - threadpoolctl==3.5.0\n",
            "      - tokenizers==0.19.1\n",
            "      - tomli==2.0.1\n",
            "      - toolz==0.12.1\n",
            "      - torch==2.2.2\n",
            "      - torchdata==0.7.1\n",
            "      - tqdm==4.66.4\n",
            "      - transformers==4.41.2\n",
            "      - triton==2.2.0\n",
            "      - trl==0.8.6\n",
            "      - typing-extensions==4.12.2\n",
            "      - tyro==0.8.4\n",
            "      - tzdata==2024.1\n",
            "      - urllib3==2.2.2\n",
            "      - xformers==0.0.25.post1\n",
            "      - xmltodict==0.13.0\n",
            "      - xxhash==3.4.1\n",
            "      - yarl==1.9.4\n",
            "      - zipp==3.19.2\n",
            "prefix: /usr/local\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnGe03dra32v",
        "outputId": "2c98316b-d257-47de-e99b-a9aa1f771645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accelerate==0.31.0\n",
            "aiohttp==3.9.5\n",
            "aiosignal==1.3.1\n",
            "alignn==2024.4.20\n",
            "annotated-types==0.7.0\n",
            "archspec @ file:///home/conda/feedstock_root/build_artifacts/archspec_1699370045702/work\n",
            "ase==3.23.0\n",
            "async-timeout==4.0.3\n",
            "-e git+https://github.com/usnistgov/atomgpt.git@a516955aa3348e628175d024c6b16896ba34e31a#egg=atomgpt\n",
            "attrs==23.2.0\n",
            "autopep8==2.3.1\n",
            "bitsandbytes==0.43.1\n",
            "black==24.4.2\n",
            "boltons @ file:///home/conda/feedstock_root/build_artifacts/boltons_1703154663129/work\n",
            "Brotli @ file:///home/conda/feedstock_root/build_artifacts/brotli-split_1695989787169/work\n",
            "certifi==2024.6.2\n",
            "cffi @ file:///home/conda/feedstock_root/build_artifacts/cffi_1696001684923/work\n",
            "chardet==3.0.4\n",
            "charset-normalizer @ file:///home/conda/feedstock_root/build_artifacts/charset-normalizer_1698833585322/work\n",
            "click==8.1.7\n",
            "colorama @ file:///home/conda/feedstock_root/build_artifacts/colorama_1666700638685/work\n",
            "conda @ file:///home/conda/feedstock_root/build_artifacts/conda_1701731572133/work\n",
            "conda-libmamba-solver @ file:///home/conda/feedstock_root/build_artifacts/conda-libmamba-solver_1702406360642/work/src\n",
            "conda-package-handling @ file:///home/conda/feedstock_root/build_artifacts/conda-package-handling_1691048088238/work\n",
            "conda_package_streaming @ file:///home/conda/feedstock_root/build_artifacts/conda-package-streaming_1691009212940/work\n",
            "contourpy==1.2.1\n",
            "cycler==0.12.1\n",
            "datasets==2.20.0\n",
            "dgl==1.1.1\n",
            "dill==0.3.8\n",
            "distro @ file:///home/conda/feedstock_root/build_artifacts/distro_1675116244235/work\n",
            "docstring_parser==0.16\n",
            "eval_type_backport==0.2.0\n",
            "filelock==3.15.4\n",
            "flake8==7.1.0\n",
            "fonttools==4.53.0\n",
            "frozenlist==1.4.1\n",
            "fsspec==2024.5.0\n",
            "gmpy2==2.2.1\n",
            "huggingface-hub==0.23.4\n",
            "idna==3.7\n",
            "importlib_resources==6.4.0\n",
            "jarvis-tools==2024.4.30\n",
            "Jinja2==3.1.4\n",
            "joblib==1.4.2\n",
            "jsonpatch @ file:///home/conda/feedstock_root/build_artifacts/jsonpatch_1695536281965/work\n",
            "jsonpointer @ file:///home/conda/feedstock_root/build_artifacts/jsonpointer_1695397238043/work\n",
            "kiwisolver==1.4.5\n",
            "libmambapy @ file:///home/conda/feedstock_root/build_artifacts/mamba-split_1702310393080/work/libmambapy\n",
            "lmdb==1.4.1\n",
            "mamba @ file:///home/conda/feedstock_root/build_artifacts/mamba-split_1702310393080/work/mamba\n",
            "markdown-it-py==3.0.0\n",
            "MarkupSafe==2.1.5\n",
            "matplotlib==3.9.0\n",
            "mccabe==0.7.0\n",
            "mdurl==0.1.2\n",
            "menuinst @ file:///home/conda/feedstock_root/build_artifacts/menuinst_1702317041727/work\n",
            "mpmath==1.3.0\n",
            "multidict==4.7.6\n",
            "multiprocess==0.70.16\n",
            "mypy-extensions==1.0.0\n",
            "networkx==3.3\n",
            "numpy==1.26.4\n",
            "nvidia-cublas-cu12==12.1.3.1\n",
            "nvidia-cuda-cupti-cu12==12.1.105\n",
            "nvidia-cuda-nvrtc-cu12==12.1.105\n",
            "nvidia-cuda-runtime-cu12==12.1.105\n",
            "nvidia-cudnn-cu12==8.9.2.26\n",
            "nvidia-cufft-cu12==11.0.2.54\n",
            "nvidia-curand-cu12==10.3.2.106\n",
            "nvidia-cusolver-cu12==11.4.5.107\n",
            "nvidia-cusparse-cu12==12.1.0.106\n",
            "nvidia-nccl-cu12==2.19.3\n",
            "nvidia-nvjitlink-cu12==12.6.20\n",
            "nvidia-nvtx-cu12==12.1.105\n",
            "packaging==24.1\n",
            "pandas==2.2.2\n",
            "pathspec==0.12.1\n",
            "peft==0.11.1\n",
            "pillow==10.3.0\n",
            "platformdirs==4.2.2\n",
            "pluggy @ file:///home/conda/feedstock_root/build_artifacts/pluggy_1693086607691/work\n",
            "protobuf==5.27.3\n",
            "psutil==6.0.0\n",
            "pyarrow==16.1.0\n",
            "pyarrow-hotfix==0.6\n",
            "pycodestyle==2.12.0\n",
            "pycosat @ file:///home/conda/feedstock_root/build_artifacts/pycosat_1696355758174/work\n",
            "pycparser @ file:///home/conda/feedstock_root/build_artifacts/pycparser_1636257122734/work\n",
            "pydantic==2.7.4\n",
            "pydantic-settings==2.3.3\n",
            "pydantic_core==2.18.4\n",
            "pydocstyle==6.3.0\n",
            "pyflakes==3.2.0\n",
            "Pygments==2.18.0\n",
            "pyparsing==2.4.7\n",
            "PySocks @ file:///home/conda/feedstock_root/build_artifacts/pysocks_1661604839144/work\n",
            "python-dateutil==2.9.0.post0\n",
            "python-dotenv==1.0.1\n",
            "pytz==2024.1\n",
            "PyYAML==6.0.2\n",
            "regex==2024.5.15\n",
            "requests==2.32.3\n",
            "rich==13.7.1\n",
            "ruamel.yaml @ file:///home/conda/feedstock_root/build_artifacts/ruamel.yaml_1699007337104/work\n",
            "ruamel.yaml.clib @ file:///home/conda/feedstock_root/build_artifacts/ruamel.yaml.clib_1695996839082/work\n",
            "safetensors==0.4.3\n",
            "scikit-learn==1.5.0\n",
            "scipy==1.13.1\n",
            "sentencepiece==0.2.0\n",
            "shtab==1.7.1\n",
            "six==1.16.0\n",
            "snowballstemmer==2.2.0\n",
            "spglib==2.4.0\n",
            "sympy==1.13.1\n",
            "threadpoolctl==3.5.0\n",
            "tokenizers==0.19.1\n",
            "tomli==2.0.1\n",
            "toolz==0.12.1\n",
            "torch==2.2.2\n",
            "torchdata==0.7.1\n",
            "tqdm==4.66.4\n",
            "transformers==4.41.2\n",
            "triton==2.2.0\n",
            "trl==0.8.6\n",
            "truststore @ file:///home/conda/feedstock_root/build_artifacts/truststore_1694154605758/work\n",
            "typing_extensions==4.12.2\n",
            "tyro==0.8.4\n",
            "tzdata==2024.1\n",
            "urllib3==2.2.2\n",
            "xformers==0.0.25.post1\n",
            "xmltodict==0.13.0\n",
            "xxhash==3.4.1\n",
            "yarl==1.9.4\n",
            "zipp==3.19.2\n",
            "zstandard==0.22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda env export"
      ],
      "metadata": {
        "id": "zkNYlup4mNHL",
        "outputId": "3e6dd98c-2915-49e2-e674-6946fa172eff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name: base\n",
            "channels:\n",
            "  - conda-forge\n",
            "dependencies:\n",
            "  - _libgcc_mutex=0.1=conda_forge\n",
            "  - _openmp_mutex=4.5=2_gnu\n",
            "  - archspec=0.2.2=pyhd8ed1ab_0\n",
            "  - boltons=23.1.1=pyhd8ed1ab_0\n",
            "  - brotli-python=1.1.0=py310hc6cd4ac_1\n",
            "  - bzip2=1.0.8=hd590300_5\n",
            "  - c-ares=1.24.0=hd590300_0\n",
            "  - ca-certificates=2023.11.17=hbcca054_0\n",
            "  - cffi=1.16.0=py310h2fee648_0\n",
            "  - charset-normalizer=3.3.2=pyhd8ed1ab_0\n",
            "  - colorama=0.4.6=pyhd8ed1ab_0\n",
            "  - conda=23.11.0=py310hff52083_1\n",
            "  - conda-libmamba-solver=23.12.0=pyhd8ed1ab_0\n",
            "  - conda-package-handling=2.2.0=pyh38be061_0\n",
            "  - conda-package-streaming=0.9.0=pyhd8ed1ab_0\n",
            "  - distro=1.8.0=pyhd8ed1ab_0\n",
            "  - fmt=10.1.1=h00ab1b0_1\n",
            "  - icu=73.2=h59595ed_0\n",
            "  - jsonpatch=1.33=pyhd8ed1ab_0\n",
            "  - jsonpointer=2.4=py310hff52083_3\n",
            "  - keyutils=1.6.1=h166bdaf_0\n",
            "  - krb5=1.21.2=h659d440_0\n",
            "  - ld_impl_linux-64=2.40=h41732ed_0\n",
            "  - libarchive=3.7.2=h2aa1ff5_1\n",
            "  - libcurl=8.5.0=hca28451_0\n",
            "  - libedit=3.1.20191231=he28a2e2_2\n",
            "  - libev=4.33=hd590300_2\n",
            "  - libffi=3.4.2=h7f98852_5\n",
            "  - libgcc-ng=13.2.0=h807b86a_3\n",
            "  - libgomp=13.2.0=h807b86a_3\n",
            "  - libiconv=1.17=hd590300_2\n",
            "  - libmamba=1.5.5=had39da4_0\n",
            "  - libmambapy=1.5.5=py310h39ff949_0\n",
            "  - libnghttp2=1.58.0=h47da74e_1\n",
            "  - libnsl=2.0.1=hd590300_0\n",
            "  - libsolv=0.7.27=hfc55251_0\n",
            "  - libsqlite=3.44.2=h2797004_0\n",
            "  - libssh2=1.11.0=h0841786_0\n",
            "  - libstdcxx-ng=13.2.0=h7e041cc_3\n",
            "  - libuuid=2.38.1=h0b41bf4_0\n",
            "  - libxml2=2.12.3=h232c23b_0\n",
            "  - libzlib=1.2.13=hd590300_5\n",
            "  - lz4-c=1.9.4=hcb278e6_0\n",
            "  - lzo=2.10=h516909a_1000\n",
            "  - mamba=1.5.5=py310h51d5547_0\n",
            "  - menuinst=2.0.1=py310hff52083_0\n",
            "  - ncurses=6.4=h59595ed_2\n",
            "  - openssl=3.2.0=hd590300_1\n",
            "  - pip=23.3.2=pyhd8ed1ab_0\n",
            "  - pluggy=1.3.0=pyhd8ed1ab_0\n",
            "  - pybind11-abi=4=hd8ed1ab_3\n",
            "  - pycosat=0.6.6=py310h2372a71_0\n",
            "  - pycparser=2.21=pyhd8ed1ab_0\n",
            "  - pysocks=1.7.1=pyha2e5f31_6\n",
            "  - python=3.10.13=hd12c33a_0_cpython\n",
            "  - python_abi=3.10=4_cp310\n",
            "  - readline=8.2=h8228510_1\n",
            "  - reproc=14.2.4.post0=hd590300_1\n",
            "  - reproc-cpp=14.2.4.post0=h59595ed_1\n",
            "  - ruamel.yaml=0.18.5=py310h2372a71_0\n",
            "  - ruamel.yaml.clib=0.2.7=py310h2372a71_2\n",
            "  - setuptools=68.2.2=pyhd8ed1ab_0\n",
            "  - tk=8.6.13=noxft_h4845f30_101\n",
            "  - truststore=0.8.0=pyhd8ed1ab_0\n",
            "  - wheel=0.42.0=pyhd8ed1ab_0\n",
            "  - xz=5.2.6=h166bdaf_0\n",
            "  - yaml-cpp=0.8.0=h59595ed_0\n",
            "  - zstandard=0.22.0=py310h1275a96_0\n",
            "  - zstd=1.5.5=hfc55251_0\n",
            "  - pip:\n",
            "      - accelerate==0.31.0\n",
            "      - aiohttp==3.9.5\n",
            "      - aiosignal==1.3.1\n",
            "      - alignn==2024.4.20\n",
            "      - annotated-types==0.7.0\n",
            "      - ase==3.23.0\n",
            "      - async-timeout==4.0.3\n",
            "      - attrs==23.2.0\n",
            "      - autopep8==2.3.1\n",
            "      - bitsandbytes==0.43.1\n",
            "      - black==24.4.2\n",
            "      - certifi==2024.6.2\n",
            "      - chardet==3.0.4\n",
            "      - click==8.1.7\n",
            "      - contourpy==1.2.1\n",
            "      - cycler==0.12.1\n",
            "      - datasets==2.20.0\n",
            "      - dgl==1.1.1\n",
            "      - dill==0.3.8\n",
            "      - docstring-parser==0.16\n",
            "      - eval-type-backport==0.2.0\n",
            "      - filelock==3.15.4\n",
            "      - flake8==7.1.0\n",
            "      - fonttools==4.53.0\n",
            "      - frozenlist==1.4.1\n",
            "      - fsspec==2024.5.0\n",
            "      - gmpy2==2.1.5\n",
            "      - huggingface-hub==0.23.4\n",
            "      - idna==3.7\n",
            "      - importlib-resources==6.4.0\n",
            "      - jarvis-tools==2024.4.30\n",
            "      - jinja2==3.1.4\n",
            "      - joblib==1.4.2\n",
            "      - kiwisolver==1.4.5\n",
            "      - lmdb==1.4.1\n",
            "      - markdown-it-py==3.0.0\n",
            "      - markupsafe==2.1.5\n",
            "      - matplotlib==3.9.0\n",
            "      - mccabe==0.7.0\n",
            "      - mdurl==0.1.2\n",
            "      - mpmath==1.3.0\n",
            "      - multidict==4.7.6\n",
            "      - multiprocess==0.70.16\n",
            "      - mypy-extensions==1.0.0\n",
            "      - networkx==3.3\n",
            "      - numpy==1.26.4\n",
            "      - nvidia-cublas-cu12==12.1.3.1\n",
            "      - nvidia-cuda-cupti-cu12==12.1.105\n",
            "      - nvidia-cuda-nvrtc-cu12==12.1.105\n",
            "      - nvidia-cuda-runtime-cu12==12.1.105\n",
            "      - nvidia-cudnn-cu12==8.9.2.26\n",
            "      - nvidia-cufft-cu12==11.0.2.54\n",
            "      - nvidia-curand-cu12==10.3.2.106\n",
            "      - nvidia-cusolver-cu12==11.4.5.107\n",
            "      - nvidia-cusparse-cu12==12.1.0.106\n",
            "      - nvidia-nccl-cu12==2.19.3\n",
            "      - nvidia-nvjitlink-cu12==12.5.40\n",
            "      - nvidia-nvtx-cu12==12.1.105\n",
            "      - packaging==24.1\n",
            "      - pandas==2.2.2\n",
            "      - pathspec==0.12.1\n",
            "      - peft==0.11.1\n",
            "      - pillow==10.3.0\n",
            "      - platformdirs==4.2.2\n",
            "      - psutil==6.0.0\n",
            "      - pyarrow==16.1.0\n",
            "      - pyarrow-hotfix==0.6\n",
            "      - pycodestyle==2.12.0\n",
            "      - pydantic==2.7.4\n",
            "      - pydantic-core==2.18.4\n",
            "      - pydantic-settings==2.3.3\n",
            "      - pydocstyle==6.3.0\n",
            "      - pyflakes==3.2.0\n",
            "      - pygments==2.18.0\n",
            "      - pyparsing==2.4.7\n",
            "      - python-dateutil==2.9.0.post0\n",
            "      - python-dotenv==1.0.1\n",
            "      - pytz==2024.1\n",
            "      - pyyaml==6.0.1\n",
            "      - regex==2024.5.15\n",
            "      - requests==2.32.3\n",
            "      - rich==13.7.1\n",
            "      - safetensors==0.4.3\n",
            "      - scikit-learn==1.5.0\n",
            "      - scipy==1.13.1\n",
            "      - sentencepiece==0.2.0\n",
            "      - shtab==1.7.1\n",
            "      - six==1.16.0\n",
            "      - snowballstemmer==2.2.0\n",
            "      - spglib==2.4.0\n",
            "      - sympy==1.12.1\n",
            "      - threadpoolctl==3.5.0\n",
            "      - tokenizers==0.19.1\n",
            "      - tomli==2.0.1\n",
            "      - toolz==0.12.1\n",
            "      - torch==2.2.2\n",
            "      - torchdata==0.7.1\n",
            "      - tqdm==4.66.4\n",
            "      - transformers==4.41.2\n",
            "      - triton==2.2.0\n",
            "      - trl==0.8.6\n",
            "      - typing-extensions==4.12.2\n",
            "      - tyro==0.8.4\n",
            "      - tzdata==2024.1\n",
            "      - urllib3==2.2.2\n",
            "      - xformers==0.0.25.post1\n",
            "      - xmltodict==0.13.0\n",
            "      - xxhash==3.4.1\n",
            "      - yarl==1.9.4\n",
            "      - zipp==3.19.2\n",
            "prefix: /usr/local\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "opxC-PlXmQtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2cW8QpTombNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# env=\"\"\"name:base\n",
        "# channels:\n",
        "#   - xformers\n",
        "#   - pytorch\n",
        "#   - nvidia\n",
        "#   - conda-forge\n",
        "#   - defaults\n",
        "# dependencies:\n",
        "#   - _libgcc_mutex=0.1=conda_forge\n",
        "#   - _openmp_mutex=4.5=2_gnu\n",
        "#   - blas=1.0=mkl\n",
        "#   - bzip2=1.0.8=h7f98852_4\n",
        "#   - ca-certificates=2024.2.2=hbcca054_0\n",
        "#   - cairo=1.18.0=h3faef2a_0\n",
        "#   - cffi=1.16.0=py39h7a31438_0\n",
        "#   - cuda-cudart=12.1.105=0\n",
        "#   - cuda-cupti=12.1.105=0\n",
        "#   - cuda-libraries=12.1.0=0\n",
        "#   - cuda-nvrtc=12.1.105=0\n",
        "#   - cuda-nvtx=12.1.105=0\n",
        "#   - cuda-opencl=12.4.99=0\n",
        "#   - cuda-runtime=12.1.0=0\n",
        "#   - cudatoolkit=11.7.0=hd8887f6_10\n",
        "#   - expat=2.5.0=hcb278e6_1\n",
        "#   - filelock=3.15.4=pyhd8ed1ab_0\n",
        "#   - font-ttf-dejavu-sans-mono=2.37=hab24e00_0\n",
        "#   - font-ttf-inconsolata=3.000=h77eed37_0\n",
        "#   - font-ttf-source-code-pro=2.038=h77eed37_0\n",
        "#   - font-ttf-ubuntu=0.83=hab24e00_0\n",
        "#   - fontconfig=2.14.2=h14ed4e7_0\n",
        "#   - fonts-conda-ecosystem=1=0\n",
        "#   - fonts-conda-forge=1=0\n",
        "#   - freetype=2.12.1=h267a509_2\n",
        "#   - gettext=0.21.1=h27087fc_0\n",
        "#   - gmp=6.3.0=h59595ed_1\n",
        "#   - gmpy2=2.1.2=py39h376b7d2_1\n",
        "#   - icu=73.2=h59595ed_0\n",
        "#   - intel-openmp=2022.1.0=h9e868ea_3769\n",
        "#   - jinja2=3.1.4=pyhd8ed1ab_0\n",
        "#   - ld_impl_linux-64=2.40=h41732ed_0\n",
        "#   - libblas=3.9.0=16_linux64_mkl\n",
        "#   - libcblas=3.9.0=16_linux64_mkl\n",
        "#   - libcublas=12.1.0.26=0\n",
        "#   - libcufft=11.0.2.4=0\n",
        "#   - libcufile=1.9.0.20=0\n",
        "#   - libcurand=10.3.5.119=0\n",
        "#   - libcusolver=11.4.4.55=0\n",
        "#   - libcusparse=12.0.2.55=0\n",
        "#   - libexpat=2.5.0=hcb278e6_1\n",
        "#   - libffi=3.4.2=h7f98852_5\n",
        "#   - libgcc-ng=13.2.0=h807b86a_2\n",
        "#   - libgfortran-ng=13.2.0=h69a702a_5\n",
        "#   - libgfortran5=13.2.0=ha4646dd_5\n",
        "#   - libglib=2.78.0=hebfc3b9_0\n",
        "#   - libgomp=13.2.0=h807b86a_2\n",
        "#   - libiconv=1.17=h166bdaf_0\n",
        "#   - liblapack=3.9.0=16_linux64_mkl\n",
        "#   - libnpp=12.0.2.50=0\n",
        "#   - libnsl=2.0.0=h7f98852_0\n",
        "#   - libnvjitlink=12.1.105=0\n",
        "#   - libnvjpeg=12.1.1.14=0\n",
        "#   - libopenblas=0.3.26=pthreads_h413a1c8_0\n",
        "#   - libpng=1.6.39=h753d276_0\n",
        "#   - libprotobuf=3.21.12=hfc55251_2\n",
        "#   - libsqlite=3.43.0=h2797004_0\n",
        "#   - libstdcxx-ng=13.2.0=h7e041cc_2\n",
        "#   - libuuid=2.38.1=h0b41bf4_0\n",
        "#   - libxcb=1.15=h0b41bf4_0\n",
        "#   - libxml2=2.11.5=h232c23b_1\n",
        "#   - libzlib=1.2.13=hd590300_5\n",
        "#   - llvm-openmp=15.0.7=h0cdce71_0\n",
        "#   - markupsafe=2.1.5=py39hd1e30aa_0\n",
        "#   - mkl=2022.1.0=hc2b9512_224\n",
        "#   - mpc=1.3.1=hfe3b2da_0\n",
        "#   - mpfr=4.2.1=h9458935_0\n",
        "#   - mpmath=1.3.0=pyhd8ed1ab_0\n",
        "#   - ncurses=6.4=hcb278e6_0\n",
        "#   - networkx=3.2.1=pyhd8ed1ab_0\n",
        "#   - ninja=1.11.1=h924138e_0\n",
        "#   - openbabel=3.1.1=py39h421517d_8\n",
        "#   - openssl=3.2.1=hd590300_1\n",
        "#   - pcre2=10.40=hc3806b6_0\n",
        "#   - pip=23.2.1=pyhd8ed1ab_0\n",
        "#   - pixman=0.42.2=h59595ed_0\n",
        "#   - pthread-stubs=0.4=h36c2ea0_1001\n",
        "#   - pycparser=2.22=pyhd8ed1ab_0\n",
        "#   - python=3.9.18=h0755675_0_cpython\n",
        "#   - python_abi=3.9=4_cp39\n",
        "#   - pytorch=2.2.2=py3.9_cuda12.1_cudnn8.9.2_0\n",
        "#   - pytorch-cuda=12.1=ha16c6d3_5\n",
        "#   - pytorch-mutex=1.0=cuda\n",
        "#   - pyyaml=6.0.1=py39hd1e30aa_1\n",
        "#   - readline=8.2=h8228510_1\n",
        "#   - setuptools=68.2.2=pyhd8ed1ab_0\n",
        "#   - sleef=3.5.1=h9b69904_2\n",
        "#   - sympy=1.12=pypyh9d50eac_103\n",
        "#   - tk=8.6.13=h2797004_0\n",
        "#   - torchtriton=2.2.0=py39\n",
        "#   - typing_extensions=4.10.0=pyha770c72_0\n",
        "#   - wheel=0.43.0=pyhd8ed1ab_1\n",
        "#   - xformers=0.0.25.post1=py39_cu12.1.0_pyt2.2.2\n",
        "#   - xorg-kbproto=1.0.7=h7f98852_1002\n",
        "#   - xorg-libice=1.1.1=hd590300_0\n",
        "#   - xorg-libsm=1.2.4=h7391055_0\n",
        "#   - xorg-libx11=1.8.7=h8ee46fc_0\n",
        "#   - xorg-libxau=1.0.11=hd590300_0\n",
        "#   - xorg-libxdmcp=1.1.3=h7f98852_0\n",
        "#   - xorg-libxext=1.3.4=h0b41bf4_2\n",
        "#   - xorg-libxrender=0.9.11=hd590300_0\n",
        "#   - xorg-renderproto=0.11.1=h7f98852_1002\n",
        "#   - xorg-xextproto=7.3.0=h0b41bf4_1003\n",
        "#   - xorg-xproto=7.0.31=h7f98852_1007\n",
        "#   - xz=5.2.6=h166bdaf_0\n",
        "#   - yaml=0.2.5=h7f98852_2\n",
        "#   - zlib=1.2.13=hd590300_5\n",
        "#   - pip:\n",
        "#       - accelerate==0.31.0\n",
        "#       - aiohttp==3.9.5\n",
        "#       - aiosignal==1.3.1\n",
        "#       - alignn==2024.4.20\n",
        "#       - annotated-types==0.7.0\n",
        "#       - ase==3.23.0\n",
        "#       - async-timeout==4.0.3\n",
        "#       - attrs==23.2.0\n",
        "#       - autopep8==2.3.1\n",
        "#       - bitsandbytes==0.43.1\n",
        "#       - black==24.4.2\n",
        "#       - certifi==2024.6.2\n",
        "#       - chardet==3.0.4\n",
        "#       - charset-normalizer==3.3.2\n",
        "#       - click==8.1.7\n",
        "#       - contourpy==1.2.1\n",
        "#       - cycler==0.12.1\n",
        "#       - datasets==2.20.0\n",
        "#       - dgl==1.1.1\n",
        "#       - dill==0.3.8\n",
        "#       - docstring-parser==0.16\n",
        "#       - eval-type-backport==0.2.0\n",
        "#       - flake8==7.1.0\n",
        "#       - fonttools==4.53.0\n",
        "#       - frozenlist==1.4.1\n",
        "#       - fsspec==2024.5.0\n",
        "#       - huggingface-hub==0.23.4\n",
        "#       - idna==3.7\n",
        "#       - importlib-resources==6.4.0\n",
        "#       - jarvis-tools==2024.4.30\n",
        "#       - joblib==1.4.2\n",
        "#       - kiwisolver==1.4.5\n",
        "#       - lmdb==1.4.1\n",
        "#       - markdown-it-py==3.0.0\n",
        "#       - matplotlib==3.9.0\n",
        "#       - mccabe==0.7.0\n",
        "#       - mdurl==0.1.2\n",
        "#       - multidict==4.7.6\n",
        "#       - multiprocess==0.70.16\n",
        "#       - mypy-extensions==1.0.0\n",
        "#       - numpy==1.26.4\n",
        "#       - packaging==24.1\n",
        "#       - pandas==2.2.2\n",
        "#       - pathspec==0.12.1\n",
        "#       - peft==0.11.1\n",
        "#       - pillow==10.3.0\n",
        "#       - platformdirs==4.2.2\n",
        "#       - psutil==6.0.0\n",
        "#       - pyarrow==16.1.0\n",
        "#       - pyarrow-hotfix==0.6\n",
        "#       - pycodestyle==2.12.0\n",
        "#       - pydantic==2.7.4\n",
        "#       - pydantic-core==2.18.4\n",
        "#       - pydantic-settings==2.3.3\n",
        "#       - pydocstyle==6.3.0\n",
        "#       - pyflakes==3.2.0\n",
        "#       - pygments==2.18.0\n",
        "#       - pyparsing==2.4.7\n",
        "#       - python-dateutil==2.9.0.post0\n",
        "#       - python-dotenv==1.0.1\n",
        "#       - pytz==2024.1\n",
        "#       - regex==2024.5.15\n",
        "#       - requests==2.32.3\n",
        "#       - rich==13.7.1\n",
        "#       - safetensors==0.4.3\n",
        "#       - scikit-learn==1.5.0\n",
        "#       - scipy==1.13.1\n",
        "#       - sentencepiece==0.2.0\n",
        "#       - shtab==1.7.1\n",
        "#       - six==1.16.0\n",
        "#       - snowballstemmer==2.2.0\n",
        "#       - spglib==2.4.0\n",
        "#       - threadpoolctl==3.5.0\n",
        "#       - tokenizers==0.19.1\n",
        "#       - tomli==2.0.1\n",
        "#       - toolz==0.12.1\n",
        "#       - torchdata==0.7.1\n",
        "#       - tqdm==4.66.4\n",
        "#       - transformers==4.41.2\n",
        "#       - trl==0.8.6\n",
        "#       - tyro==0.8.4\n",
        "#       - tzdata==2024.1\n",
        "#       - urllib3==2.2.2\n",
        "#       - xmltodict==0.13.0\n",
        "#       - xxhash==3.4.1\n",
        "#       - yarl==1.9.4\n",
        "#       - zipp==3.19.2\n",
        "# \"\"\"\n",
        "# with open(f'/content/conda.yaml', 'w') as f:\n",
        "#     f.write(env)\n",
        "# # !conda env update --name base -f conda.yaml"
      ],
      "metadata": {
        "id": "jvEq4Wu0mbPp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}